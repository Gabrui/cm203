{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14c563d",
   "metadata": {},
   "source": [
    "**Aeronautics Institute of Technology – ITA**\n",
    "\n",
    "**Computer Vision – CM-203**\n",
    "\n",
    "**Professors:** \n",
    "\n",
    "Marcos Ricardo Omena de Albuquerque Maximo\n",
    "\n",
    "Gabriel Adriano de Melo\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Before submitting your lab, be sure that everything is running correctly (in sequence): first, **restart the kernel** (`Runtime->Restart Runtime` in Colab or `Kernel->Restart` in Jupyter). Then, execute all cells (`Runtime->Run All` in Colab or `Cell->Run All` in Jupyter) and verifies that all cells run without any errors, expecially the automatic grading ones, i.e. the ones with `assert`s.\n",
    "\n",
    "**Do not delete the answer cells**, i.e. the ones that contains `WRITE YOUR CODE HERE` or `WRITE YOUR ANSWER HERE`, because they contain metadata with the ids of the cells for the grading system. For the same reason, **do not delete the test cells**, i.e. the ones with `assert`s. The autograding system executes all the code sequentially, adding extra tests in the test cells. There is no problem in creating new cells, as long as you do not delete answer or test cells. Moreover, keep your solutions within the reserved spaces.\n",
    "\n",
    "The notebooks are implemented to be compatible with Google Colab, and they install the dependencies and download the datasets automatically. The commands which start with ! (exclamation mark) are bash commands and can be executed in a Linux terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22093594",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c11b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d1bbb59fa108faa3366e302f9e51481",
     "grade": false,
     "grade_id": "cell-552f2456b881ed4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Laboratory 9 - Generator Adversarial Network (GAN)\n",
    "\n",
    "In this laboratory, you will implement the DCGAN (Deep Convolutional Generative Adversarial Network) technique to generate fake images of cats.\n",
    "This laboratory was based on many tutorials available on the Internet. Therefore, I incentivize that you try to implement the functions without looking for DCGAN tutorials. Of course, you can check the libraries' documentations and other websites. Moreover, do not copy code from tutorials. Remember that the intention here is that you learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47bc573",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2c0f1b6132e84a8acc6fc30f55d6b75",
     "grade": false,
     "grade_id": "cell-6ecc803e1e2f9316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Installations and Configurations\n",
    "\n",
    "The following cells install dependencies and configure the notebook for the implementation of the laboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3368d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975ba0e594e0f8acc799b5cd62c756d4",
     "grade": false,
     "grade_id": "cell-82cb89d26b333d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib torch torchvision tqdm opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ca5a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "574789647f02055e40d87c84f90a3d9d",
     "grade": false,
     "grade_id": "cell-31753d5589c0a4b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Imports\n",
    "\n",
    "The following cell imports the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd05edb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d50418ef40d16030d4e223a0488501e",
     "grade": false,
     "grade_id": "cell-c252d4ff7c174620",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import  os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ceb01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c27ac190a606228b4b92e668c4715310",
     "grade": false,
     "grade_id": "cell-4ed77e92de2ecdf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell defines a function for resetting the random seeds\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "  # 42 is the answer to the Ultimate Question of Life, the Universe, and Everything\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405a962",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ce4a7343d5820a2610e9bc0d42c7016",
     "grade": false,
     "grade_id": "cell-270e157595a067ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e15afc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a90cfd0fd52a6cfd078b85e3b9857d2",
     "grade": false,
     "grade_id": "cell-1dfc4dfdafc76b75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "The following cell downloads a dataset with many pictures of cute cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d3403",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a87d236cf0ef710c5b763d2830146c90",
     "grade": false,
     "grade_id": "cell-c678944d71bf0025",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('archive.zip'):\n",
    "    !gdown https://drive.google.com/uc?id=1WrW8nXvYFafz5qNY9Mi8tU32Y-Z2M0Zd\n",
    "if not os.path.exists('cats'):\n",
    "    !unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0003d50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "210179fd4ec935d552ceb55ae918836b",
     "grade": false,
     "grade_id": "cell-fb07bba4a703f0cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81261d36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc03020228651f2305048912e128aef6",
     "grade": false,
     "grade_id": "cell-2bcad7ae889f2c67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Visualizing the Dataset\n",
    "\n",
    "The following cell shows some pictures of the data. Beware of cuteness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b138d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33deb031ec455ea76cad39c71c8004c4",
     "grade": false,
     "grade_id": "cell-2cf1a3f6a27af670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "grid_size = 8\n",
    "num_imgs = grid_size * grid_size\n",
    "fig = plt.figure(figsize=(grid_size, grid_size))\n",
    "for num, fn in enumerate(os.listdir(DATA_DIR + '/cats')[:num_imgs]):\n",
    "    path = DATA_DIR + '/cats/' + fn\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(grid_size, grid_size, num + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d1d17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4aabd5675b26434ec215bc09bc50470",
     "grade": false,
     "grade_id": "cell-1fdf8169f3e6a1d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Creating the Data Loader\n",
    "\n",
    "The following cell creates a data loader which resizes and normalize the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e2cdd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4f52a16e5c481f95d2fe158a2e81827",
     "grade": false,
     "grade_id": "cell-6c59563604de8f5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 128\n",
    "normalize_mean = [0.5, 0.5, 0.5]\n",
    "normalize_std = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_ds = ImageFolder(DATA_DIR + '/cats', transform=tt.Compose([\n",
    "    tt.Resize(image_size),\n",
    "    tt.CenterCrop(image_size),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=normalize_mean, std=normalize_std)\n",
    "]))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfe67c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6697c765ad75acc53146b6bfd9d91123",
     "grade": false,
     "grade_id": "cell-b207053e1e5b4b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Defining some variables\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "latent_size = 100 # the dimension of the latent space used in the generator\n",
    "size_multiplier = 64 # multiplier used to define the number of filters at each layer\n",
    "num_color_channels = 3 # number of color channels of the input image\n",
    "learning_rate = 0.0002 # learning rate used in the optimization algorithm\n",
    "beta1 = 0.5 # hyperparameter beta1 of the Adam optimization algorithm\n",
    "beta2 = 0.999 # hyperparameter beta2 of the Adam optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da523b9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77284bb653fb970c61302e0884cc2f65",
     "grade": false,
     "grade_id": "cell-8ad3770425d30a5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementing the Generator\n",
    "\n",
    "In the following cell, implement the generator network.\n",
    "\n",
    "Instructions:\n",
    "- The architecture of the network is based on the DCGAN architecture, but is not exactly the same.\n",
    "- Five convolutional-transpose layers are used to convert the latent space into a 3x64x64 image.\n",
    "- Each convolutional-transpose layer uses a kernel size of 4.\n",
    "- The stride of the first convolutional-transpose layer is 1, while the other ones use stride of 2.\n",
    "- No padding is used in the first convolutional-transpose layer, but the subsequent ones use a padding of 1.\n",
    "- No bias is used in the convolutional-transpose layers.\n",
    "- The intermediary layers use the ReLU activation function, while the last one uses Tanh.\n",
    "- Batch Normalization is used after each convolutional-transpose layer, except for the last one.\n",
    "- Use `size_multiplier` to help you obtain the correct dimensions at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a85e7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6075073d6aac7db47252a36770664c7",
     "grade": false,
     "grade_id": "generator_network",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines the generator network of the DCGAN technique.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor of the generator.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # in: latent_size x 1 x 1\n",
    "            nn.ConvTranspose2d(latent_size, 8 * size_multiplier, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(8 * size_multiplier),\n",
    "            nn.ReLU(True),\n",
    "            # tensor: 512 x 4 x 4        \n",
    "            nn.ConvTranspose2d(8 * size_multiplier, 4 * size_multiplier, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(4 * size_multiplier),\n",
    "            nn.ReLU(True),\n",
    "            # tensor: 256 x 8 x 8\n",
    "            # Implement the next layers:\n",
    "            # tensor: 128 x 16 x 16\n",
    "            # tensor: 64 x 32 x 32\n",
    "            # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "            raise NotImplementedError()\n",
    "            nn.ConvTranspose2d(size_multiplier, num_color_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "            # out: 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae55eff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1192b05716e5107370aa81eda10de1d9",
     "grade": false,
     "grade_id": "cell-b6c3142b19ff69dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Prints the generator network\n",
    "generator = Generator().to(device)\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459499bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bef1f3e94ce1afc0b14e928d18e40cd8",
     "grade": false,
     "grade_id": "cell-44ec9714f81b7ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Auxiliary function to count the number of trainable parameters of a PyTorch model.\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae91bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "158884a830cd9989311cdd4003b8af63",
     "grade": true,
     "grade_id": "generator_network_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "generator = Generator().to(device)\n",
    "\n",
    "assert count_parameters(generator) == 3576704\n",
    "\n",
    "latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "\n",
    "output = generator.forward(latent)\n",
    "\n",
    "assert output.shape[0] == batch_size\n",
    "assert output.shape[1] == num_color_channels\n",
    "assert output.shape[2] == image_size\n",
    "assert output.shape[3] == image_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0767a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "639fdfab6b4dd0e145877ae27f98efbb",
     "grade": false,
     "grade_id": "cell-89444523c6c15c18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement the Discriminator\n",
    "\n",
    "In the following cell, implement the discriminator.\n",
    "\n",
    "Instructions:\n",
    "- The architecture of the network is based on the DCGAN architecture, but is not exactly the same.\n",
    "- Five convolutional layers are used to transform the input image into a scalar which encodes the probability of the image being a real one.\n",
    "- Each convolutional layer uses a kernel size of 4.\n",
    "- The stride of the last convolutional layer is 1, while the other ones use stride of 2.\n",
    "- No padding is used in the last convolutional layer, but the previous ones use a padding of 1.\n",
    "- No bias is used in the convolutional layers.\n",
    "- The intermediary layers use the LeakyReLU activation function with a negative slope of 0.2, while the last one uses Sigmoid.\n",
    "- Batch Normalization is used after each convolutional layer, except for the last one.\n",
    "- Use `size_multiplier` to help you obtain the correct dimensions at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133965c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd31e9731a9223b406f7f93f253357f5",
     "grade": false,
     "grade_id": "discriminator_network",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # in: 3 x 64 x 64\n",
    "            nn.Conv2d(num_color_channels, size_multiplier, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(size_multiplier),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # tensor: 64 x 32 x 32\n",
    "            # Implement the next layers:\n",
    "            # tensor: 128 x 16 x 16\n",
    "            # tensor: 256 x 32 x 32\n",
    "            # tensor: 512 x 4 x 4       \n",
    "            # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "            raise NotImplementedError()\n",
    "            nn.Conv2d(8 * size_multiplier, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            # out: 1 x 1 x 1\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8a2b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be4bf1ae74c9c788a2aecf7d58564593",
     "grade": false,
     "grade_id": "cell-125cd3bfd608c5be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Prints the discriminator network\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a7fb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f34b39f6cb669fd1e492322e7304b7d9",
     "grade": true,
     "grade_id": "discriminator_network_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "assert count_parameters(discriminator) == 2765696\n",
    "\n",
    "random_img = torch.randn(batch_size, num_color_channels, image_size, image_size, device=device)\n",
    "\n",
    "output = discriminator.forward(random_img)\n",
    "\n",
    "assert output.shape[0] == batch_size\n",
    "assert output.shape[1] == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b9b78",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cbded3edc326f816fbf812aeafc946f",
     "grade": false,
     "grade_id": "cell-28eebe27171d19a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Initializing the Weights\n",
    "\n",
    "In DCGAN, the weights are initialized in a particular way. The weights of the convolutional and convolutional-tranpose layers are initialized with a Normal distribution with zero mean and standard deviation of 0.02. Notice that the convolutional and convolutional-transpose do not have biases in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88712b55",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1a10c9442015fc327576e3d95b211a4",
     "grade": false,
     "grade_id": "weights_init",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    Initializes the weights of a given layer following the DCGAN convention.\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "        raise NotImplementedError()\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b472bcf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb521f44239eac03b15eda87edcf5506",
     "grade": true,
     "grade_id": "weights_init_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "\n",
    "discriminator.apply(weights_init)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "assert (torch.sum(discriminator.network[0].weight.data) - (-1.0316)) < 1e-3\n",
    "assert (torch.sum(discriminator.network[1].weight.data) - 64.0033) < 1e-3\n",
    "\n",
    "assert (torch.sum(generator.network[0].weight.data) - 5.0504) < 1e-3\n",
    "assert (torch.sum(generator.network[1].weight.data) - 512.3093) < 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd6cac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7dae3b06e3577edd2a8f42f575e33c2",
     "grade": false,
     "grade_id": "cell-2fa467b791b99b6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "def save_samples(index, latent_tensors, show=True):\n",
    "    \"\"\"\n",
    "    Auxiliary function to save the generated samples during training.\n",
    "    \"\"\"\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated_images_{0:0=4d}.png'.format(index)\n",
    "    save_image(fake_images, os.path.join(sample_dir, fake_fname), nrow=8, padding=2, normalize=True)\n",
    "    print('Saving ', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a58bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43c07046b0eb2f621f2f9a670fa65fd8",
     "grade": false,
     "grade_id": "cell-01aa53370b279db4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementing the Discriminator's Training\n",
    "\n",
    "To train the discriminator, we use the following loss function:\n",
    "\\begin{equation}\n",
    "J^{(D)} = -\\mathbb{E}_{x \\sim p_{\\mathrm{data}}} \\log D(x) - \\mathbb{E}_z \\log \\left( 1 - D(G(z)) \\right),\n",
    "\\end{equation}\n",
    "where the first and second terms are the losses related to the real and fake (i.e. generated by the generator) images, respectively. Using this loss function, implement an iteration of the discriminator's training in the following cell.\n",
    "Hints:\n",
    "- Use `F.binary_cross_entropy(predictions, targets)` for computing the binary cross-entropy between `predictions` and `targets`.\n",
    "- To learn how to generate fake images, have a look at the test of the generator network.\n",
    "- Use the code related to how the real loss is computed as a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0790db03",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e33eac06d4df5fb8d3fe6c78ab42c38",
     "grade": false,
     "grade_id": "training_step_discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def training_step_discriminator(discriminator, generator, real_images, opt_d):\n",
    "    \"\"\"\n",
    "    Executes an iteration of the discriminator's training.\n",
    "    param discriminator: the discriminator's model.\n",
    "    param generator: the generator's model.\n",
    "    param real_images: real images from the dataset.\n",
    "    param opt_d: the optimizer used to execute a step of Gradient Descent.\n",
    "    return: three value are returned: the total loss, the score from the \n",
    "            real images, and the score from the fake images.\n",
    "    \"\"\"\n",
    "    opt_d.zero_grad()\n",
    "    \n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Create fake images and their targets\n",
    "    # Compute the fake loss using binary cross-entropy\n",
    "    # Use how the real loss is computed as a template\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    \n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2fdfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf9fcfc1f299e1a11a6d2995df5da2a3",
     "grade": true,
     "grade_id": "training_step_discriminator_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "discriminator.apply(weights_init)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "\n",
    "real_images = generator(latent) # Using them as real images, but they are fake\n",
    "loss_d, real_score, fake_score = training_step_discriminator(discriminator, generator, real_images.to(device), opt_d)\n",
    "\n",
    "assert (loss_d - 1.8112266063690186) < 1e-3\n",
    "assert (real_score - 0.6484211087226868) < 1e-3\n",
    "assert (fake_score - 0.6575933694839478) < 1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03941db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac6cbf18e911fd557d713be369aca7e0",
     "grade": false,
     "grade_id": "cell-6320f008afe1b22f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementing the Generator's Training\n",
    "\n",
    "To train the generator, use as loss function:\n",
    "\\begin{equation}\n",
    "J^{(G)} = -\\mathbb{E}_z \\log \\left( D(G(z)) \\right).\n",
    "\\end{equation}\n",
    "Using this loss function, implement an iteration of the generator's training in the following cell.\n",
    "Hints:\n",
    "- Use `F.binary_cross_entropy(predictions, targets)` for computing the binary cross-entropy between `predictions` and `targets`.\n",
    "- To learn how to generate fake images, have a look at the test of the generator network.\n",
    "- Use the code related to how the real loss is computed in the discriminator's training step as a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14c4bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a92e047df5d146c36ecc50a87ece4217",
     "grade": false,
     "grade_id": "training_step_generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def training_step_generator(discriminator, generator, opt_g):\n",
    "    \"\"\"\n",
    "    Executes an iteration of the discriminator's training.\n",
    "    param discriminator: the discriminator's model.\n",
    "    param generator: the generator's model.\n",
    "    param opt_g: the optimizer used to execute a step of Gradient Descent.\n",
    "    return: the loss value.\n",
    "    \"\"\"\n",
    "    opt_g.zero_grad()\n",
    "\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265a84d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cc7422e727d766decf7bd0589e5e0c6",
     "grade": true,
     "grade_id": "training_step_generator_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "discriminator.apply(weights_init)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "opt_g = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "\n",
    "real_images = generator(latent) # Using them as real images, but they are fake\n",
    "loss_g = training_step_generator(discriminator, generator, opt_g)\n",
    "\n",
    "assert (loss_g - 0.49504929780960083) < 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb6c12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afb0c9b13e566b9f3655cce6269a8612",
     "grade": false,
     "grade_id": "cell-982197e937670cf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generating a fixed latent vector so we can compare results from different epochs\n",
    "reset_seeds()\n",
    "\n",
    "fixed_latent = torch.randn(batch_size, latent_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a619e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "299c27af273230f2ab92224a35e31dc1",
     "grade": false,
     "grade_id": "cell-541bdd375f2d19d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implementing the Training\n",
    "\n",
    "As mentioned in class, the training of the discriminator and the generator are interleaved. In the following function, implement the training step considering that we first execute a training step of the discriminator, then a training step of the generator. **Hint:** take a look at the tests of the training step functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc8e7a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1094d8a05575741f76d0ceb1e3ff1c8d",
     "grade": false,
     "grade_id": "fit_step",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_step(discriminator, generator, real_images, opt_d, opt_g):\n",
    "    \"\"\"\n",
    "    Executes a step of the DCGAN training.\n",
    "    :param discriminator: the discriminator's model.\n",
    "    :param generator: the generator's model.\n",
    "    :param real_images: the real images.\n",
    "    :param opt_d: the discriminator's optimizer.\n",
    "    :param opt_g: the generator's optimizer.\n",
    "    :return: the discriminator's loss, the generator's loss, the score related to the real images, and\n",
    "             the score related to the fake images.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return loss_d, loss_g, real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015bd48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ba885a6461d0c4a43611806b1cddf77",
     "grade": true,
     "grade_id": "fit_step_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "discriminator.apply(weights_init)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "real_images, _ = next(iter(train_dl))\n",
    "fit_step(discriminator, generator, real_images, opt_d, opt_g)\n",
    "\n",
    "assert (torch.sum(discriminator.network[0].weight.data) - (-1.0316)) < 1e-3\n",
    "assert (torch.sum(discriminator.network[1].weight.data) - 64.0033) < 1e-3\n",
    "\n",
    "assert (torch.sum(generator.network[0].weight.data) - 5.0504) < 1e-3\n",
    "assert (torch.sum(generator.network[1].weight.data) - 512.3093) < 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863720f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6700ac5a09ffd2f89a3a3ea8c77e455f",
     "grade": false,
     "grade_id": "fit",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit(num_epochs, learning_rate, start_idx=1, show=False, autograding=False):\n",
    "    \"\"\"\n",
    "    Trains the DCGAN.\n",
    "    param num_epochs: number of epochs used in the training.\n",
    "    param learning_rate: learning rate used for the optimizers.\n",
    "    param start_idx: start index of the epochs (used if training is resumed).\n",
    "    param show: if the training results should be shown during training.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Create the optimizers\n",
    "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "    opt_g = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for real_images, _ in tqdm(train_dl):\n",
    "            # Executes a step of the training\n",
    "            loss_d, loss_g, real_score, fake_score = fit_step(discriminator, generator, real_images.to(device), opt_d, opt_g)\n",
    "            \n",
    "        # Log losses and scores from the last batch\n",
    "        print('Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}'.format(\n",
    "            epoch + 1, num_epochs, loss_g, loss_d, real_score, fake_score\n",
    "        ))\n",
    "\n",
    "        save_samples(epoch + start_idx, fixed_latent, show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716df244",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d2a34b00a4279d71ef7b1e4210f9604",
     "grade": false,
     "grade_id": "cell-645b747f975ddf84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training More\n",
    "\n",
    "Training for a single epoch gives results that resembles faint images of cats. For better quality, we need to train for more time. The following cell trains the GAN for 10 epochs.\n",
    "\n",
    "You definitely need a GPU for executing this training. This training is optional, but I highly recommend you execute it to see the results. You can get much better quality with even more training.\n",
    "\n",
    "To see the results, look for a folder called `generated` in your computer or in Google Colab.\n",
    "\n",
    "Even with 10 epochs, the cats will still look like cute furry demons :). You can also see the evolution across the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791eb53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d967645ec7a43a911d1ddd5bba950dd",
     "grade": true,
     "grade_id": "final_training",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reset_seeds()\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "discriminator.apply(weights_init)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "num_epochs = 10\n",
    "fit(num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c7069",
   "metadata": {},
   "source": [
    "# Your data and feedback:\n",
    "\n",
    "Write a feedback for the lab so we can make it better for the next years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b65339",
   "metadata": {},
   "source": [
    "In the following variables, write the number of hours spent on this lab, the perceived difficulty, and the expected grade (you may delete the `raise` and the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb5779",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f613d80a345c28aaf937672ec9e9f5",
     "grade": true,
     "grade_id": "meta_eval",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# meta_eval manual_graded_answer 0\n",
    "\n",
    "horas_gastas = None    # 1.5   - Float number with the number of hours spent \n",
    "dificuldade_lab = None # 0     - Float number from 0.0 to 10.0 (inclusive)\n",
    "nota_esperada = None   # 10    - Float number from 0.0 to 10.0 (inclusive)\n",
    "\n",
    "# WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f94778",
   "metadata": {},
   "source": [
    "Write below other comments or feedbacks about the lab. If you did not understand anything about the lab, please also comment here.\n",
    "\n",
    "If you find any typo or bug in the lab, please comment below so we can fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fca3b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc6431aff9a971fe5ed82c62bc668c96",
     "grade": true,
     "grade_id": "meta_eval_discursivo",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "WRITE YOUR SOLUTION HERE! (do not change this first line):\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**DISCURSIVE QUESTION**\n",
    "\n",
    "WRITE YOUR ANSWER HERE (do not delete this cell so the ID is not lost)\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb87cf5",
   "metadata": {},
   "source": [
    "**End of the lab!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
