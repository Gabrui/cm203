{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773820d9",
   "metadata": {},
   "source": [
    "**Aeronautics Institute of Technology – ITA**\n",
    "\n",
    "**Computer Vision – CM-203**\n",
    "\n",
    "**Professors:** \n",
    "\n",
    "Marcos Ricardo Omena de Albuquerque Maximo\n",
    "\n",
    "Gabriel Adriano de Melo\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Before submitting your lab, be sure that everything is running correctly (in sequence): first, **restart the kernel** (`Runtime->Restart Runtime` in Colab or `Kernel->Restart` in Jupyter). Then, execute all cells (`Runtime->Run All` in Colab or `Cell->Run All` in Jupyter) and verifies that all cells run without any errors, expecially the automatic grading ones, i.e. the ones with `assert`s.\n",
    "\n",
    "**Do not delete the answer cells**, i.e. the ones that contains `WRITE YOUR CODE HERE` or `WRITE YOUR ANSWER HERE`, because they contain metadata with the ids of the cells for the grading system. For the same reason, **do not delete the test cells**, i.e. the ones with `assert`s. The autograding system executes all the code sequentially, adding extra tests in the test cells. There is no problem in creating new cells, as long as you do not delete answer or test cells. Moreover, keep your solutions within the reserved spaces.\n",
    "\n",
    "The notebooks are implemented to be compatible with Google Colab, and they install the dependencies and download the datasets automatically. The commands which start with ! (exclamation mark) are bash commands and can be executed in a Linux terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bafe26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b19d6",
   "metadata": {},
   "source": [
    "# Laboratório de Odometria\n",
    "\n",
    "Neste laboratório iremos aplicar os nossos conhecimentos anteriores de visão estéreo, perpectiva de n pontos e de RANSAC em um problema de odometria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e796f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se for executar localmente, tenha as seguintes bibliotecas instaladas\n",
    "# !pip3 install opencv-contrib-python==4.6.0.66 Pillow==7.1.2 matplotlib==3.2.2 scipy==1.7.3 gdown==4.4.0\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba10d6",
   "metadata": {},
   "source": [
    "Se for executar local e quiser alterar o Path, pode alterar aqui sem problemas para a correção automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13570ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fb0d329072791151d7b0d361ab1a3a6",
     "grade": false,
     "grade_id": "baixa_dados",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "! [ ! -d \"/content/odometria\" ] && gdown -O /content/odometria.zip 1JanfRR4dJk6tfhpm_hTNRBkkNzoy7gpL && unzip /content/odometria.zip -d /content && rm /content/odometria.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676942a",
   "metadata": {},
   "source": [
    "Vamos carregar parte das imagens e dos dados de tempos, de calibração e de referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c87146",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c94fdae9705e85ae316451e49d2be8",
     "grade": false,
     "grade_id": "carrega_dados",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "root_path = Path(\"/content/odometria\")\n",
    "tempos = np.loadtxt(str(root_path/'tempos.txt'))\n",
    "imgs_esq = [cv2.imread(str(p), cv2.IMREAD_ANYCOLOR) for p in sorted((root_path/'esquerda').glob('*.png'))[:N]]\n",
    "proj_esq = np.loadtxt(str(root_path/'calib.txt'), dtype=np.float32)[0].reshape(3, 4)\n",
    "imgs_dir = [cv2.imread(str(p), cv2.IMREAD_ANYCOLOR) for p in sorted((root_path/'direita').glob('*.png'))[:N]]\n",
    "proj_dir = np.loadtxt(str(root_path/'calib.txt'), dtype=np.float32)[1].reshape(3, 4)\n",
    "refs = np.loadtxt(str(root_path/'referencia.txt'), dtype=np.float32).reshape(-1, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa77cfe",
   "metadata": {},
   "source": [
    "## Operações de Odometria\n",
    "\n",
    "Para o caso da odometria monocular, é necessário um parâmetro de escala para conseguir estabelecer a distância percorrida (nas unidades de comprimento) entre dois quadros. Esse fator de escala pode ser oriundo de sensores inerciais ou de ainda algum outro sensor associade à unidade de comprimento (como um velocímetro). Dessa forma, vamos acabar derivando a velocidade a partir dos dados de posição de referência (que foram obtidas de fusão de sensores inerciais e de posição).\n",
    "\n",
    "Implemente a função abaixo que deriva a velocidade a partir das matrizes de pose. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use apenas indexação de matrizes do numpy e também `np.linalg.norm` aplicado apenas em um eixo `axis` específico.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06d968",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d2314eabb8077913ecb9ccd31e303c1",
     "grade": false,
     "grade_id": "velocidade",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calcula_velocidade(posicoes, tempos):\n",
    "    \"\"\"\n",
    "    Calcula a velocidade a partir de matrizes de pose e de um vetor de tempo por meio de diferenças finitas\n",
    "    :param posicoes: Matrizes de pose (n, 3, 4) em metros [R_mat | T_vec]\n",
    "    :param delta_t: Vetor do tempo (n, ) associada a cada posição em segundos, crescente\n",
    "    Retorna vetor de velocidades lineares em m/s calculada por diferenças finitas progressivas (diferença da próxima\n",
    "    posição para a atual).\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return velocidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003819a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "622625bb7e3d71da49f5116c14bbf230",
     "grade": true,
     "grade_id": "testa_velocidade",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "velos = calcula_velocidade(refs[:11], tempos[:11])\n",
    "assert np.linalg.norm(velos - np.array([1.22559295, 1.37714263, 1.58089024, 1.71854421, 1.85536711,\n",
    "       1.99962678, 2.11304293, 2.24617   , 2.38809648, 2.5471701 ])) < 1e-4\n",
    "velocidades = calcula_velocidade(refs[:len(tempos)], tempos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78e1a",
   "metadata": {},
   "source": [
    "Dados deste laboratório foram extraídos do [KITTI](https://www.cvlibs.net/datasets/kitti/) (Karlsruhe Institute of Technology and Toyota Technological Institute) e servem como benchmark de algoritmos de localização para carros autônomos (apesar de que para um dataset de mais de 10 anos, já tivemos uma significativa evolução dos sensores).\n",
    "\n",
    "Neste laboratório iremos utilizar apenas as câmeras mono da esquerda (Cam 0) e da direita (Cam 1), além dos dados de calibração e de referência (para comparação). Perceba que o referencial da câmera da esquerda está próximo ao centro de massa o do carro (a menos da altura) e será utilizado como o sistema de coordenadas do carro.\n",
    "\n",
    "Perceba que a direção do Z é a frente, a direção do X é da lateral direita do carro e a direção do Y é para baixo.\n",
    "\n",
    "![Posição das câmeras no carro](https://www.cvlibs.net/datasets/kitti/images/setup_top_view.png)\n",
    "\n",
    "As imagens estéreo já foram retificadas (`R_mat = np.eye(3)`) e des-distorcidas, de tal forma que a há uma única componente de translação horizontal entre as câmeras. Encontre esse vetor a partir da matriz de projeção (a matriz que leva pontos no espaço 3d para pontos homogêneos em pixels 2d, resultado de `mtx @ [R_mat | t_vec]`) e também a matrix intrínseca `mtx`. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use apenas indexação de matrizes do numpy.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e1d26",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1689feea633b7eab5d4fd9177e8c73ed",
     "grade": false,
     "grade_id": "decomp",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def matriz_projecao_para_mtx_T(matriz_projecao):\n",
    "    \"\"\"\n",
    "    Decompõe a matrix de projeção na matriz intríseca e no vetor de translação, considerando um sistema de câmeras\n",
    "    já retificadas horizontalmente (não há rotação e apenas translação horizontal)\n",
    "    :param matriz_projecao: matriz de projeção 3x4 resultado de mtx @ [R_mat | t_vec]\n",
    "    Retorna a matriz_intrinseca mtx 3x3 em pixels e o vetor de translação t_vec 3x1 em metros.\n",
    "    Na resposta não é para chamar nenhuma função do OpenCV, é para calcular manualmente\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return matriz_intrinseca, vetor_translacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d77971",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9db69eec13414d5f56b34d0c5d104d0",
     "grade": true,
     "grade_id": "testa_decomp",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P = np.array([[50, 0, 100, 100],[0, 50, 100, 0],[0, 0, 1, 0]])\n",
    "mtx, t_vec = matriz_projecao_para_mtx_T(P)\n",
    "assert np.all(mtx == np.array([[50, 0, 100], [0, 50, 100], [0, 0, 1]]))\n",
    "assert np.all(t_vec == np.array([[2],[0],[0]]))\n",
    "\n",
    "mtx_esq, t_esq = matriz_projecao_para_mtx_T(proj_esq)\n",
    "mtx_dir, t_dir = matriz_projecao_para_mtx_T(proj_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b53f35",
   "metadata": {},
   "source": [
    "Outra operação essencial de odometria é reconstruir a trajetória absoluta a partir dos vetores de deslocamento e das matrizes de rotação relativas extraídas de cada frame. Observe que é nessa operação que os erros se propagam e aumentam com o tempo (drifting) uma vez que se realiza a soma (vetorial) dos deslocamentos.\n",
    "\n",
    "Assim, implemente a função abaixo que realiza essa transformação de coordenadas encadeada para obter a trajetória com relação à pose inicial. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Basta usar multiplicação de matrizes no numpy, o operador `a @ b` que é equivalente a `np.matmul(a, b)`. Não vai me confundir a rotação (pensando que é para calcular a inversa) e a translação (pensando que é para subtrair), as matrizes e os vetores já estão representados como deslocamentos (que levam do atual para o próximo).\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe829e12",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c0c1de5796fd969e476a759f0ae5930",
     "grade": false,
     "grade_id": "trajetoria",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reconstroi_trajetoria(lista_matrizes_rotacao, lista_vetores_deslocamento):\n",
    "    \"\"\"\n",
    "    Reconstroi a trajetória a partir da origem (a ser incluída como primeiro ponto da saída).\n",
    "    :param lista_matrizes_rotacao: lista de matrizes de rotação 3x3 que descreve a rotação da próxima pose com \n",
    "                                   relação à atual\n",
    "    :param lista_matrizes_rotacao: lista de vetores de deslocamento 3x1 que descreve o deslocamento da próxima \n",
    "                                   pose com relação à atual\n",
    "    Retorna a lista de rotações e translações  com relação à origem.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return lista_rotacao_absoluta, lista_posicao_absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8da14f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67b7304ee255ff41b5865f92e2cfdff8",
     "grade": true,
     "grade_id": "testa_trajetoria",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rmats, tvecs = reconstroi_trajetoria([R.from_euler('XYZ',[0,np.pi/4,0]).as_matrix()]*8, [np.array([[0],[0],[1]])]*8)\n",
    "assert np.linalg.norm(rmats[0] - np.eye(3)) < 1e-6\n",
    "assert np.linalg.norm(tvecs[0] - np.zeros(3)) < 1e-6\n",
    "assert np.linalg.norm(rmats[8] - np.eye(3)) < 1e-6\n",
    "assert np.linalg.norm(tvecs[8] - np.zeros(3)) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212cfa8",
   "metadata": {},
   "source": [
    "Veja a trajetória de exemplo abaixo que se desloca 1 metro para a frente e vira 45º para a direita a cada passo:\n",
    "\n",
    "OBS: Seguindo a convenção do sistema de coordenadas do carro, plotamos os eixos X e Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80322dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "rmats,tvecs=reconstroi_trajetoria([R.from_euler('XYZ',[0,2*np.pi/n,0]).as_matrix()]*n, [np.array([[0],[0],[1]])]*n)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([p[0,0] for p in tvecs], [p[2,0] for p in tvecs], 'o-')\n",
    "plt.xlabel('Posição X (m)')\n",
    "plt.ylabel('Posição Z (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279245a2",
   "metadata": {},
   "source": [
    "## Odometria Monocular (com dados externos de velocidade)\n",
    "\n",
    "O passo mais simples da odometria é utilizar imagens apenas de uma câmera para conseguir estimar a pose relativa entre dois frames. O problema é que não é possível determinar o fator de escala entre as imagens, dessa forma é necessário conhecer ou a escala (distância) de pelo menos um ponto ou ainda a escala (distância) entre as duas poses, que no caso pode ser facilmente obtida conhecendo-se a velocidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdede69",
   "metadata": {},
   "source": [
    "O primeiro passo da odometria é calcular o deslocamento 2d entre os pontos projetados na imagem. Podemos fazer isso de forma esparsa, com um detector de features (que detecta pontos salientes na imagem com seus descritores) e um correlacionador dessas features, que tenta \n",
    "\n",
    "Outra alternativa que veremos a seguir é justamente calcular o fluxo óptico entre as duas imagens, selecionando apenas os pontos de maior distinção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.ORB_create(nfeatures=4500, scaleFactor=1.19)\n",
    "relacionador = cv2.FlannBasedMatcher(indexParams={\n",
    "    'algorithm':6, 'table_number':6, 'key_size':12, 'multi_probe_level':1}, searchParams={'checks': 50})\n",
    "\n",
    "def pegar_pontos_iguais(img1, img2):\n",
    "    \"\"\"\n",
    "    Recebe duas imagens e retorna as coords. de pontos correspondentes nx2\n",
    "    \"\"\"\n",
    "    pontos1, descritores1 = detector.detectAndCompute(img1, None)\n",
    "    pontos2, descritores2 = detector.detectAndCompute(img2, None)\n",
    "    relacoes = relacionador.knnMatch(descritores1, descritores2, k=2)\n",
    "    relacoes_fortes = [r1 for r1, r2 in relacoes if r1.distance < 0.7 * r2.distance]\n",
    "    pts1 = np.array([pontos1[r.queryIdx].pt for r in relacoes_fortes], dtype=np.float32)\n",
    "    pts2 = np.array([pontos2[r.trainIdx].pt for r in relacoes_fortes], dtype=np.float32)\n",
    "    return pts1, pts2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4e533",
   "metadata": {},
   "source": [
    "Veja abaixo, por exemplo, a relação encontrada para os pontos entre duas imagens consecutivas:\n",
    "\n",
    "Na realidade peguei uma imagem 3 quadros passados para ficar maiores os deslocamentos e também a rotação maior (para o corretor automático)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc15867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fut, pts = pegar_pontos_iguais(imgs_esq[47], imgs_esq[44])\n",
    "img = np.repeat(imgs_esq[44][:, :, None], 3, axis=-1)\n",
    "for pfut, p in zip(pts_fut, pts): # Desenha uma linha ligando os pares de pontos\n",
    "    cv2.line(img, np.uint(p), np.uint(pfut), (250, 250, 0))\n",
    "PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801800f",
   "metadata": {},
   "source": [
    "Como o primeiro passo em geral resulta em uma grande quantidade de outlier, no segundo passo de encontrar a matriz essencial (que é posteriormente decomposta na matriz de rotação e translação), utiliza-se o RANSAC.\n",
    "\n",
    "Relembrando que a matriz essencial ($\\mathbf  {E}$) é o resultado do produto entre a matriz de rotação e a matriz de translação do produto vetorial $\\mathbf  {E}=\\mathbf  {R}\\,[\\mathbf  {t}]_{\\times }$, onde $[\\mathbf  {t}]_{\\times }$ é a representação matricial da operação de produto vetorial:\n",
    "\n",
    "$\\mathbf {a} \\times \\mathbf {b} =[\\mathbf {a} ]_{\\times }\\mathbf {b} ={\\begin{bmatrix}\\,0&\\!-a_{3}&\\,\\,a_{2}\\\\,\\,a_{3}&0&\\!-a_{1}\\\\-a_{2}&\\,\\,a_{1}&\\,0\\end{bmatrix}}{\\begin{bmatrix}b_{1}\\\\b_{2}\\\\b_{3}\\end{bmatrix}}$\n",
    "\n",
    "Para estimar a matriz essencial são necessário pelo menos 8 pares de pontos (no mínimo é 7 mas 8 é mais estável). Dessa forma o RANSAC fará amostras aleatórias de 8 pares de pontos e calculará a matriz essencial (o modelo). As distâncias dos pontos até as suas linhas epipolares são utilizadas como limiar para determinar se um ponto é ou não outlier para o modelo. Assim, escolhe-se o modelo com a maior quantidade de inliers.\n",
    "\n",
    "Implemente a função abaixo que simplesmente chama a função `cv2.recoverPose` do OpenCV. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86d801",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b83ea57befae23c86b70830d7181319",
     "grade": false,
     "grade_id": "pose_mono",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estima_rotacao_translacao(pts_futuro, pts_atual, mtx, metodo=cv2.USAC_ACCURATE, confianca=0.9999, dist=2):\n",
    "    \"\"\"\n",
    "    Utiliza a função cv2.recoverPose que calcula a matriz essencial (e faz a sua decomposição na rotação e \n",
    "    translação) a partir dos pares de pontos. Utilize o método de cv2.USAC_ACCURATE, que é mais eficiente do\n",
    "    que o velho RANSAC.\n",
    "    :param pts_futuro: Matriz de pontos 2d nx2 na imagem futura\n",
    "    :param pts_atual: Matriz de pontos 2d nx2 relacionados ao pts_futuro\n",
    "    :param mtx: Matriz intrínseca da câmera, a imagem já foi des-distorcida\n",
    "    :param confianca: Probabilidade de acerto do RANSAC\n",
    "    :param dist: Limiar de distância entre o ponto e o modelo (linha epipolar) para considerar outlier\n",
    "    Retorna a matriz de rotação e o vetor de translação normalizado, além da máscara dos inliers.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return matriz_rotacao, direcao_translacao, inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e9291",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beb1adcbdc747299cb4c049ed3759415",
     "grade": true,
     "grade_id": "testa_pose_mono",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(1)\n",
    "cv2.setRNGSeed(42)\n",
    "\n",
    "mtx_esq, t_esq = matriz_projecao_para_mtx_T(proj_esq)\n",
    "pts_fut, pts = pegar_pontos_iguais(imgs_esq[47], imgs_esq[44])\n",
    "rmat, tvec, mask = estima_rotacao_translacao(pts_fut, pts, mtx_esq)\n",
    "assert np.linalg.norm(rmat - np.array(\n",
    "       [[ 0.99590877,  0.00659954,  0.09012309],\n",
    "        [-0.00645422,  0.99997736, -0.00190382],\n",
    "        [-0.09013362,  0.00131436,  0.99592881]])) < 1e-2\n",
    "assert np.linalg.norm(tvec - np.array(\n",
    "       [[ 0.05638571],\n",
    "        [-0.0194907 ],\n",
    "        [ 0.9982188 ]])) < 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9361683",
   "metadata": {},
   "source": [
    "Veja como ficam os outliers (em vermelho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b486ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.repeat(imgs_esq[44][:, :, None], 3, axis=-1)\n",
    "for pfut, p, inlier in zip(pts_fut, pts, mask.ravel()): # Desenha uma linha ligando os pares de pontos\n",
    "    cor = (255, 0, 0)\n",
    "    if inlier:\n",
    "        cor = (0, 255, 0)\n",
    "    cv2.line(img, np.int32(p), np.int32(pfut), cor)\n",
    "PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6ffc1",
   "metadata": {},
   "source": [
    "Agora vamos corrigir a escala do vetor de translação, dado a nossa velocidade estimada e um intervado de tempo. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fdc3e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d2988c350746886b47edd15a6a8259c",
     "grade": false,
     "grade_id": "corrige_escala",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def corrige_escala(vetor_translacao, velocidade, delta_t):\n",
    "    \"\"\"\n",
    "    Aplica a escala no vetor deslocamento, usando a aproximação de primeira ordem (linear).\n",
    "    :param vetor_translacao: Vetor de translação/deslocamento 3x1\n",
    "    :param velocidade: Escalar da velocidade (m/s)\n",
    "    :param delta_t: Escalar do intervalo de tempo considerado (segundos)\n",
    "    Retorna o vetor de translação dimensionalizado (m) pela velocidade\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return vetor_dimensionalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc75cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bb413cac134dcd72284858a32dcb3d6",
     "grade": true,
     "grade_id": "testa_corrige_escala",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.linalg.norm(corrige_escala(np.array([[3],[2],[8]]), 1, 1) - np.array([[3],[2],[8]])) < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8460a",
   "metadata": {},
   "source": [
    "Finalmente juntamos todas as funções que implementamos até agora. Implemente a função abaixo. (3 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde21b02",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a60f8bb4fbef08b9b32f2f926c12800",
     "grade": false,
     "grade_id": "odo_mono",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def odometria_mono(imgs, mtx, velocidades, tempos):\n",
    "    \"\"\"\n",
    "    Recebe uma sequência de imagens tiradas de uma mesma câmera, e reconstroe a trajetória percorrida.\n",
    "    Utilize a imagem imediatamente subsequente para estimar a pose relativa de cada imagem da sequência.\n",
    "    :param imgs: lista de imagens de escala de cinza\n",
    "    :param mtx: matriz intrínseca da câmera, a imagem já está des-distorcida\n",
    "    :param velocidades: vetor de velocidades (m/s)\n",
    "    :param tempos: vetor de tempos (s)\n",
    "    Usa a função pegar_pontos_iguais que recebe duas imagens e retorna duas matrizes de pontos2d\n",
    "    Retorna a trajetória percorrida, reconstruída tomando-se o primeiro quadro como a origem\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return np.array(lista_rotacao_absoluta), np.array(lista_posicao_absoluta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b1737",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9827119e18511fb364f16c606def5ca",
     "grade": true,
     "grade_id": "testa_odo_mono",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv2.setRNGSeed(42)\n",
    "rotacoes, posicoes = odometria_mono(imgs_esq[:70], mtx_esq, velocidades[:69], tempos[:70])\n",
    "assert np.linalg.norm(rotacoes[0] - np.eye(3)) < 1e-6\n",
    "assert np.linalg.norm(posicoes[0] - np.zeros(3)) < 1e-6\n",
    "assert np.linalg.norm(rotacoes[-1] - np.array(\n",
    "      [[-0.5063042 ,  0.04474437,  0.8611933 ],\n",
    "       [ 0.03299499,  0.9989269 , -0.03250242],\n",
    "       [-0.8617235 ,  0.01195895, -0.5072372 ]])) < 9e-2\n",
    "assert np.linalg.norm(posicoes[-1] - np.array(\n",
    "      [[38.33941  ],\n",
    "       [ 0.7189929],\n",
    "       [ 2.756405 ]])) < 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aacb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(posicoes[:, 0, 0], posicoes[:, 2, 0], 'b-o', label='Odometria')\n",
    "plt.plot(refs[:len(posicoes), 0, 3], refs[:len(posicoes), 2, 3], 'g-x', label='Referência')\n",
    "plt.legend()\n",
    "plt.xlabel('Distância em X (m)')\n",
    "plt.ylabel('Distância em Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da0e5e",
   "metadata": {},
   "source": [
    "Podemos refazer todo o processo acima, substuindo a função que faz o rastreio 2d, de um caso de features detector por fluxo optico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegar_pontos_fluxo_optico(img_fut, img):\n",
    "    p = cv2.goodFeaturesToTrack(img, maxCorners=3200, qualityLevel=0.012, minDistance=8, blockSize=5)\n",
    "    pfut, status, err = cv2.calcOpticalFlowPyrLK(img, img_fut, p, None, winSize=(15, 15))\n",
    "    valid = status.ravel().astype(np.bool8)\n",
    "    return pfut.reshape(-1, 2)[valid], p.reshape(-1, 2)[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dad5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_fut, pts = pegar_pontos_fluxo_optico(imgs_esq[47], imgs_esq[46])\n",
    "img = np.repeat(imgs_esq[46][:, :, None], 3, axis=-1)\n",
    "for pfut, p in zip(pts_fut, pts): # Desenha uma linha ligando os pares de pontos\n",
    "    cv2.line(img, np.int32(p), np.int32(pfut), (250, 250, 0))\n",
    "print(len(pts))\n",
    "PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d73d9d",
   "metadata": {},
   "source": [
    "Agora reimplemente a função acima, mas usando a função `pegar_pontos_fluxo_optico` para estabelecer o vínculo 2d. Perceba o que acontece com o resultado. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc417423",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fedbec6c506ab76e5154d58cafc2824a",
     "grade": false,
     "grade_id": "mono_lk",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def odometria_mono_LK(imgs, mtx, velocidades, tempos):\n",
    "    \"\"\"\n",
    "    Recebe uma sequência de imagens tiradas de uma mesma câmera, e reconstroe a trajetória percorrida.\n",
    "    Utilize a imagem imediatamente subsequente para estimar a pose relativa de cada imagem da sequência.\n",
    "    :param imgs: lista de imagens de escala de cinza\n",
    "    :param mtx: matriz intrínseca da câmera, a imagem já está des-distorcida\n",
    "    :param velocidades: vetor de velocidades (m/s)\n",
    "    :param tempos: vetor de tempos (s)\n",
    "    Usa a função pegar_pontos_fluxo_optico que recebe duas imagens e retorna duas matrizes de pontos2d\n",
    "    Retorna a trajetória percorrida, reconstruída tomando-se o primeiro quadro como a origem\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return np.array(lista_rotacao_absoluta), np.array(lista_posicao_absoluta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0c207",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fe607bce3dbde246c2a8e73de315752",
     "grade": true,
     "grade_id": "testa_mono_lk",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv2.setRNGSeed(42)\n",
    "rotacoes, posicoes = odometria_mono_LK(imgs_esq[:70], mtx_esq, velocidades[:69], tempos[:70])\n",
    "assert np.linalg.norm(rotacoes[0] - np.eye(3)) < 1e-6\n",
    "assert np.linalg.norm(posicoes[0] - np.zeros(3)) < 1e-6\n",
    "assert np.linalg.norm(rotacoes[-1] - np.array(\n",
    "      [[-0.5063042 ,  0.04474437,  0.8611933 ],\n",
    "       [ 0.03299499,  0.9989269 , -0.03250242],\n",
    "       [-0.8617235 ,  0.01195895, -0.5072372 ]])) < 4e-2\n",
    "assert np.linalg.norm(posicoes[-1] - np.array(\n",
    "      [[38.33941  ],\n",
    "       [ 0.7189929],\n",
    "       [ 2.756405 ]])) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(posicoes[:, 0, 0], posicoes[:, 2, 0], 'b-o', label='Odometria')\n",
    "plt.plot(refs[:len(posicoes), 0, 3], refs[:len(posicoes), 2, 3], 'g-x', label='Referência')\n",
    "plt.legend()\n",
    "plt.xlabel('Distância em X (m)')\n",
    "plt.ylabel('Distância em Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa34d90",
   "metadata": {},
   "source": [
    "## Odometria Estéreo\n",
    "\n",
    "Agora não dependemos mais da informação de velocidade externa para estabelecer a realação de escala, uma vez que conhecemos as distâncias entre as câmeras (em metros), conseguimos determinar o nosso deslocamento (em metros), a partir da triangulação de pontos que sejam identificados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ed602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegar_pontos_iguais_quad(img_esq, img_esq_fut, img_dir, img_dir_fut):\n",
    "    \"\"\"\n",
    "    Recebe quatro imagens e retorna uma lista com as coords. de pontos correspondentes nx2 por feature matching\n",
    "    \"\"\"\n",
    "    imgs = [img_esq, img_esq_fut, img_dir, img_dir_fut]\n",
    "    pts_des = [detector.detectAndCompute(img, None) for img in imgs] # Detecta e descreve bons pontos\n",
    "    # Relaciona os pontos com a primeira imagem\n",
    "    rels = [relacionador.knnMatch(des, pts_des[0][1], k=2) for pts, des in pts_des[1:]]\n",
    "    rels_filtrados = [[r1 for r1, r2 in rel if r1.distance < 0.7 * r2.distance] for rel in rels]\n",
    "    rels_t = [[r.trainIdx for r in rel] for rel in rels_filtrados]\n",
    "    rels_q = [[r.queryIdx for r in rel] for rel in rels_filtrados]\n",
    "    img0_idxs = [set(rt) for rt in rels_t]\n",
    "    idxs_comuns = img0_idxs[0].intersection(*img0_idxs[1:])\n",
    "    rels_intersect = [[rq[rt.index(i)] for i in idxs_comuns] for rt, rq in zip(rels_t, rels_q)]\n",
    "    pts0 = np.array([pts_des[0][0][idx].pt for idx in idxs_comuns], dtype=np.float32)\n",
    "    pts = [np.array([pts[idx].pt for idx in rels_intersect[i]], dtype=np.float32)\n",
    "            for i, (pts , des) in enumerate(pts_des[1:])]\n",
    "    return [pts0] + pts\n",
    "\n",
    "def pegar_pontos_fluxo_optico_quad(img_esq, img_esq_fut, img_dir, img_dir_fut):\n",
    "    \"\"\"\n",
    "    Recebe quatro imagens e retorna uma lista com as coords. de pontos correspondentes nx2 por Lukas-Kanade\n",
    "    \"\"\"\n",
    "    p0 = cv2.goodFeaturesToTrack(img_esq, maxCorners=3200, qualityLevel=0.012, minDistance=8, blockSize=5)\n",
    "    p1, status1, err = cv2.calcOpticalFlowPyrLK(img_esq, img_esq_fut, p0, None, winSize=(15, 15))\n",
    "    p2, status2, err = cv2.calcOpticalFlowPyrLK(img_esq, img_dir, p0, None, winSize=(15, 15))\n",
    "    p3, status3, err = cv2.calcOpticalFlowPyrLK(img_dir, img_dir_fut, p2, None, winSize=(15, 15))\n",
    "    # Verifica se o vínculo estéreo está satisfeito (linhas epipolares horizontais)\n",
    "    stereo1 = (np.abs(p0 - p2).reshape(-1, 2)[:, 1] < 1.2) & ((p0 - p2).reshape(-1, 2)[:, 0] > 0)\n",
    "    stereo2 = (np.abs(p1 - p3).reshape(-1, 2)[:, 1] < 1.2) & ((p1 - p3).reshape(-1, 2)[:, 0] > 0)\n",
    "    valid = ((status1 & status2 & status3).ravel() & stereo1 & stereo2).astype(np.bool8)\n",
    "    return [p.reshape(-1, 2)[valid] for p in [p0, p1, p2, p3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ce46b",
   "metadata": {},
   "source": [
    "Observe como fica o fluxo óptico de quadros de um mesmo instante entre câmeras retificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3, p4 = pegar_pontos_fluxo_optico_quad(imgs_esq[40], imgs_esq[41], imgs_dir[40], imgs_dir[41])\n",
    "img = np.repeat(imgs_esq[40][:, :, None], 3, axis=-1)\n",
    "for pfut, p in zip(p3, p1): # Desenha uma linha ligando os pares de pontos\n",
    "    cv2.line(img, np.int32(np.round(p)), np.int32(np.round(pfut)), (250, 250, 0))\n",
    "print(len(p1))\n",
    "PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.repeat(imgs_dir[40][:, :, None], 3, axis=-1)\n",
    "for pfut, p in zip(p4, p3): # Desenha uma linha ligando os pares de pontos\n",
    "    cv2.line(img, np.int32(np.round(p)), np.int32(np.round(pfut)), (250, 250, 0))\n",
    "PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87759069",
   "metadata": {},
   "source": [
    "Uma das formas mais simples de agregar dados de múltiplas câmeras é fazer a média das rotações e dos deslocamentos que cada uma percebe. O ideal seria realizar a otimização conjunta de ambas as câmeras, mas como o OpenCV não tem uma função que faça um Bundle Adjustment, vamos quebrar em várias etapas e juntar os resultados como a média das câmreras.\n",
    "\n",
    "Mas primeiro é necessário corrigir os deslocamentos, uma vez que, a translação que a câmera da direita percebe (fora do \"CG\") é diferente translação que a câmera da esquerda percebe (que está no CG). Vamos levar todos esses deslocamentos para o CG, a fim de padronizar.\n",
    "\n",
    "Implemente a função abaixo que realiza essa correção. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a7e89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f47a645801969343db3113db11708a",
     "grade": false,
     "grade_id": "compensa_cg",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compensa_cg(tvec, rotm, dist_cg):\n",
    "    \"\"\"\n",
    "    Compensa a diferença de translação que a câmera da direita tem com relação à câmera da esquerda que está na\n",
    "    origem (\"CG\") do carro\n",
    "    :param tvec: Vetor de translação 3x1 do movimento observada pela câmera da direita\n",
    "    :param rotm: Matriz de rotação 3x3 do movimento (observada por ambas as câmeras, \n",
    "                                    a rotação é a mesma para qualquer ponto no corpo)\n",
    "    :dist_cg: Vetor de translação do CG (cam esquerda) até a câmera da direita\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return tvec_compensado_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bed7d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fca95aed73b666487c03f0bb6cb164d8",
     "grade": true,
     "grade_id": "testa_compensa_cg",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.linalg.norm(np.zeros((3,1)) - \n",
    "    compensa_cg(np.array([[-1], [0], [-1]]), R.from_euler('XYZ',[0,-np.pi/2,0]).as_matrix(), \n",
    "                np.array([[1],[0],[0]]))\n",
    "                     ) < 1e-6\n",
    "assert np.linalg.norm(np.array([[1-np.sqrt(2)/2],[0],[np.sqrt(2)/2]]) - \n",
    "    compensa_cg(np.array([[0], [0], [0]]), R.from_euler('XYZ',[0,-np.pi/4,0]).as_matrix(), \n",
    "                np.array([[1],[0],[0]]))\n",
    "                     ) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42afa4",
   "metadata": {},
   "source": [
    "Essas otimizações seriam melhores se fossem feitas em conjunto para o caso estéreo, mas como o OpenCV não tem um Bundle Adjustment, iniciamos estimando a rotação e translação monocular (para cada câmera em separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86705db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, t1, m1 = estima_rotacao_translacao(p2, p1, mtx_esq)\n",
    "r2, t2, m2 = estima_rotacao_translacao(p4, p3, mtx_dir)\n",
    "inliers = (m1 & m2).ravel().astype(np.bool8)\n",
    "if np.sum(inliers) < 10: # Deixar tudo na mão do RANSAC do PnP\n",
    "    inliers = np.ones((len(m1),), dtype=np.bool8)\n",
    "media_rots = R.from_matrix([r1, r2]).mean().as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acbd33",
   "metadata": {},
   "source": [
    "Com base na triangulação dos pontos que tenham sido corretamente identificado nas 4 imagens, vamos uma triangulação para os pontos no passado e outra para os pontos do futuro. Daí já poderíamos identificar o deslocamento e a rotação entre essas nuvens de pontos, mas seria bom usar um RANSAC pois podem ter outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02743e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts4d = cv2.triangulatePoints(proj_esq, proj_dir, p1[inliers].T, p3[inliers].T)\n",
    "pts3d = pts4d[:3, :] / pts4d[3:, :]\n",
    "pts4d_fut = cv2.triangulatePoints(proj_esq, proj_dir, p2[inliers].T, p4[inliers].T)\n",
    "pts3d_fut = pts4d_fut[:3, :] / pts4d_fut[3:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0151ef",
   "metadata": {},
   "source": [
    "Como já tem um RANSAC implementado no PnP, fica mais fácil usá-lo aqui. Assim, podemos aplicar o PnP de várias formas, com a geometria triangulada no passado ou no futuro, na câmera direita ou esquerda. Lembrando que se aplicar no passado/futuro será a transformação inversa obtida (ao invés de caminhar para frente estará caminhando para trás)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35222290",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_esq, rvec_esq, tvec_esq, inliers_esq = cv2.solvePnPRansac(pts3d_fut.T, p1[inliers], mtx_esq, None)\n",
    "ok_esq_i, rvec_esq_i, tvec_esq_i, inliers_esq_i = cv2.solvePnPRansac(pts3d.T, p2[inliers], mtx_esq, None)\n",
    "ok_dir, rvec_dir, tvec_dir, inliers_dir = cv2.solvePnPRansac(pts3d_fut.T, p3[inliers], mtx_dir, None)\n",
    "ok_dir_i, rvec_dir_i, tvec_dir_i, inliers_dir_i = cv2.solvePnPRansac(pts3d.T, p4[inliers], mtx_dir, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2531903",
   "metadata": {},
   "source": [
    "Daqui já podemos usar o resultado do PnP dos pontos triangulados para fazer saber a rotação e translação (já é o resultado do PnP, só com cuidado das transformações inversas `_i` e da correção do CG para a câmera direita.\n",
    "\n",
    "O exemplo abaixo realiza a odometria apenas com o PnP de uma câmera (esquerda) e triangulação dos pontos futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = []\n",
    "for i in range(70):\n",
    "    p1, p2, p3, p4 = pegar_pontos_fluxo_optico_quad(imgs_esq[i], imgs_esq[i+1], imgs_dir[i], imgs_dir[i+1])\n",
    "    r1, t1, m1 = estima_rotacao_translacao(p2, p1, mtx_esq)\n",
    "    r2, t2, m2 = estima_rotacao_translacao(p4, p3, mtx_dir)\n",
    "    inliers = (m1 & m2).ravel().astype(np.bool8)\n",
    "    if np.sum(inliers) < 10: # Com poucos inliers o PnP quebra, colocar tudo e deixar o RANSAC\n",
    "        inliers = np.ones((len(m1),), dtype=np.bool8)\n",
    "    inter.append((p1, p2, p3, p4, r1, t1, r2, t2, inliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd58893",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_rel, t_rel = [], []\n",
    "for p1, p2, p3, p4, r1, t1, r2, t2, inliers in inter:\n",
    "    pts4d_fut = cv2.triangulatePoints(proj_esq, proj_dir, p2[inliers].T, p4[inliers].T)\n",
    "    pts3d_fut = pts4d_fut[:3, :] / pts4d_fut[3:, :]\n",
    "    ok_esq, rvec_esq, tvec_esq, inliers_esq = cv2.solvePnPRansac(pts3d_fut.T, p1[inliers], mtx_esq, None)\n",
    "    rot_rel.append(R.from_rotvec(rvec_esq.ravel()).as_matrix())\n",
    "    t_rel.append(tvec_esq)\n",
    "rs, ts = reconstroi_trajetoria(rot_rel, t_rel)\n",
    "ts = np.array(ts)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(ts[:, 0, 0], ts[:, 2, 0], 'b-o', label='Odometria')\n",
    "plt.plot(refs[:len(ts), 0, 3], refs[:len(ts), 2, 3], 'g-x', label='Referência')\n",
    "plt.legend()\n",
    "plt.xlabel('Distância em X (m)')\n",
    "plt.ylabel('Distância em Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6265a2",
   "metadata": {},
   "source": [
    "Sinta-se à vontade para explorar e modificar o código, inclusive aumentando a quantidade de imagens a serem carregadas, são 700 frames no total.\n",
    "\n",
    "Por exemplo no código abaixo já temos a média, das rotações encontradas pela matriz essencial e das translações encontradas pelo PnP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_rel, t_rel = [], []\n",
    "for p1, p2, p3, p4, r1, t1, r2, t2, inliers in inter:\n",
    "    pts4d = cv2.triangulatePoints(proj_esq, proj_dir, p1[inliers].T, p3[inliers].T)\n",
    "    pts3d = pts4d[:3, :] / pts4d[3:, :]\n",
    "    pts4d_fut = cv2.triangulatePoints(proj_esq, proj_dir, p2[inliers].T, p4[inliers].T)\n",
    "    pts3d_fut = pts4d_fut[:3, :] / pts4d_fut[3:, :]\n",
    "    ok_esq, rvec_esq, tvec_esq, inliers_esq = cv2.solvePnPRansac(pts3d_fut.T, p1[inliers], mtx_esq, None)\n",
    "    ok_esq_i, rvec_esq_i, tvec_esq_i, inliers_esq_i = cv2.solvePnPRansac(pts3d.T, p2[inliers], mtx_esq, None)\n",
    "    ok_dir, rvec_dir, tvec_dir, inliers_dir = cv2.solvePnPRansac(pts3d_fut.T, p3[inliers], mtx_dir, None)\n",
    "    ok_dir_i, rvec_dir_i, tvec_dir_i, inliers_dir_i = cv2.solvePnPRansac(pts3d.T, p4[inliers], mtx_dir, None)\n",
    "    rot_rel.append(R.from_matrix([r1, r2]).mean().as_matrix())\n",
    "    t_rel.append((tvec_esq+compensa_cg(tvec_dir, rot_rel[-1], -t_dir)-t_dir)/2)\n",
    "rs, ts = reconstroi_trajetoria(rot_rel, t_rel)\n",
    "ts = np.array(ts)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(ts[:, 0, 0], ts[:, 2, 0], 'b-o', label='Odometria')\n",
    "plt.plot(refs[:len(ts), 0, 3], refs[:len(ts), 2, 3], 'g-x', label='Referência')\n",
    "plt.legend()\n",
    "plt.xlabel('Distância em X (m)')\n",
    "plt.ylabel('Distância em Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3026d",
   "metadata": {},
   "source": [
    "# Your data and feedback:\n",
    "\n",
    "Write a feedback for the lab so we can make it better for the next years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec494a2a",
   "metadata": {},
   "source": [
    "In the following variables, write the number of hours spent on this lab, the perceived difficulty, and the expected grade (you may delete the `raise` and the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe8aae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f613d80a345c28aaf937672ec9e9f5",
     "grade": true,
     "grade_id": "meta_eval",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# meta_eval manual_graded_answer 0\n",
    "\n",
    "horas_gastas = None    # 1.5   - Float number with the number of hours spent \n",
    "dificuldade_lab = None # 0     - Float number from 0.0 to 10.0 (inclusive)\n",
    "nota_esperada = None   # 10    - Float number from 0.0 to 10.0 (inclusive)\n",
    "\n",
    "# WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f05c6",
   "metadata": {},
   "source": [
    "Write below other comments or feedbacks about the lab. If you did not understand anything about the lab, please also comment here.\n",
    "\n",
    "If you find any typo or bug in the lab, please comment below so we can fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7b0a5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc6431aff9a971fe5ed82c62bc668c96",
     "grade": true,
     "grade_id": "meta_eval_discursivo",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "WRITE YOUR SOLUTION HERE! (do not change this first line):\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**DISCURSIVE QUESTION**\n",
    "\n",
    "WRITE YOUR ANSWER HERE (do not delete this cell so the ID is not lost)\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568c0cb",
   "metadata": {},
   "source": [
    "**End of the lab!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
