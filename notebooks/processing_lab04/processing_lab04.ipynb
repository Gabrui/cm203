{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa259043",
   "metadata": {},
   "source": [
    "**Aeronautics Institute of Technology – ITA**\n",
    "\n",
    "**Computer Vision – CM-203**\n",
    "\n",
    "**Professors:** \n",
    "\n",
    "Marcos Ricardo Omena de Albuquerque Maximo\n",
    "\n",
    "Gabriel Adriano de Melo\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Before submitting your lab, be sure that everything is running correctly (in sequence): first, **restart the kernel** (`Runtime->Restart Runtime` in Colab or `Kernel->Restart` in Jupyter). Then, execute all cells (`Runtime->Run All` in Colab or `Cell->Run All` in Jupyter) and verifies that all cells run without any errors, expecially the automatic grading ones, i.e. the ones with `assert`s.\n",
    "\n",
    "**Do not delete the answer cells**, i.e. the ones that contains `WRITE YOUR CODE HERE` or `WRITE YOUR ANSWER HERE`, because they contain metadata with the ids of the cells for the grading system. For the same reason, **do not delete the test cells**, i.e. the ones with `assert`s. The autograding system executes all the code sequentially, adding extra tests in the test cells. There is no problem in creating new cells, as long as you do not delete answer or test cells. Moreover, keep your solutions within the reserved spaces.\n",
    "\n",
    "The notebooks are implemented to be compatible with Google Colab, and they install the dependencies and download the datasets automatically. The commands which start with ! (exclamation mark) are bash commands and can be executed in a Linux terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ec5fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46139365",
   "metadata": {},
   "source": [
    "In this lab, you will implement some simple algorithms for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624572cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install opencv-contrib-python==4.6.0.66 Pillow==7.1.2 matplotlib==3.2.2 scipy==1.7.3 gdown==4.4.0\n",
    "# tesseract-ocr (4.0.0-2), tesseract-ocr-eng (1:4.00)\n",
    "def install_dependencies():\n",
    "    \"\"\"Install the dependencies and restart if needed\"\"\"\n",
    "    try:\n",
    "        import pytesseract\n",
    "    except:\n",
    "        !apt install tesseract-ocr && pip install pytesseract==0.3.10\n",
    "        if 'google.colab' in str(get_ipython()):\n",
    "            import os\n",
    "            os.kill(os.getpid(), 9)\n",
    "\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62202089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def ocr(imagem):\n",
    "    \"\"\"Returns the first line of characters detected by Tesseract as a string\"\"\"\n",
    "    return pytesseract.image_to_string(imagem, config='--oem 1 --psm 7').split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa8c6b",
   "metadata": {},
   "source": [
    "The next cell download a dataset with images of container plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifies if the images have already been downloaded, and download and unzip them if necessary\n",
    "! [ ! -d \"/content/placas\" ] && gdown -O /content/placas.zip 1x7ZyRx_be-U9u0NM_rSN_3-Wb_srf-5h &&  unzip /content/placas.zip -d /content && rm /content/placas.zip\n",
    "\n",
    "imgs_path = Path(\"/content/placas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929d1f6",
   "metadata": {},
   "source": [
    "The next cell uses Tesseract, which is a Optical Character Recognition (OCR) library, to detect the letters and numbers present in a container plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048184ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = cv2.cvtColor(cv2.imread(str(imgs_path/'placa_original.jpg')), cv2.COLOR_BGR2RGB)\n",
    "print(ocr(plate))\n",
    "PIL.Image.fromarray(plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063adb1c",
   "metadata": {},
   "source": [
    "## Color to grayscale conversion\n",
    "\n",
    "A pixel in the image $I[y, x]$ is composed by its three color channels: blue $B[y, x]$, green $G[y, x]$, and red $R[y, x]$. Moreover, it follows the OpenCV convention of BGR: $I[y, x] = \\left[ B[y, x], G[y, x], R[y, x] \\right]$. Then, to convert a pixel to grayscale, we use the following linear transform:\n",
    "\n",
    "$C[y, x] = 0.114 B[y, x] + 0.587 G[y, x] + 0.299 R[y, x]$.\n",
    "\n",
    "These coefficients depend on the sensor sensibility and the screen accordingly to the human perception. The above coefficients are used for digital images accordingly to the specification ITU BT.601.\n",
    "\n",
    "Note: this transform is defined considering a linear space, i.e. when the image scale has not been transformed by the gamma coefficient: $I_\\text{nonlinear}(y, x) = I(y, x)^\\gamma$.\n",
    "\n",
    "Implement your own function below to compute this conversion (1 point). **You are not allowed** to use `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)`, so you need to implement the matrix operations using NumPy.\n",
    "\n",
    "<details><summary><b>Hints (click to expand):</b></summary>\n",
    "\n",
    "- Use `matrix.astype(np.float64)` or `matrix.astype(np.uint8)` to convert a NumPy matrix to float64 or uint8.\n",
    "\n",
    "- To obtain the image associated to a color channel, use `matrix[:, :, c]`, where `c` is the index of the color channel.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b75cbb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74873c36a4b3e242b247e26dc1577e1c",
     "grade": false,
     "grade_id": "cinza",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_bgr_to_grayscale(bgr_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts an image from BGR to grayscale using the equation:\n",
    "    C[y, x] = 0.114 * B[y, x] + 0.587 * G[y, x] + 0.299 * R[y, x]\n",
    "    :param bgr_img: matrix (H, W, 3) which represents an image with height H, width W, and 3 color channels as BGR.\n",
    "    :return: a new image (H, W) in grayscale in the 8 bits format.\n",
    "    Uses truncation when converting floats to uint8 (for autograding).\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea53293",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccf419928e84e10a0ddf7f680330e812",
     "grade": true,
     "grade_id": "testa_cinza",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img = np.arange(180, dtype=np.uint8).reshape(6, 10, 3)\n",
    "assert convert_bgr_to_grayscale(img).dtype == np.uint8\n",
    "assert np.all(convert_bgr_to_grayscale(img) == np.array(\n",
    "      [[  1,   4,   7,  10,  13,  16,  19,  22,  25,  28],\n",
    "       [ 31,  34,  37,  40,  43,  46,  49,  52,  55,  58],\n",
    "       [ 61,  64,  67,  70,  73,  76,  79,  82,  85,  88],\n",
    "       [ 91,  94,  97, 100, 103, 106, 109, 112, 115, 118],\n",
    "       [121, 124, 127, 130, 133, 136, 139, 142, 145, 148],\n",
    "       [151, 154, 157, 160, 163, 166, 169, 172, 175, 178]], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af549669",
   "metadata": {},
   "source": [
    "See the result of the conversion in an actual image below.\n",
    "\n",
    "Note: this photo is not in a linear color space, so the conversion is not perfect, but the result seems fine visually anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d685157",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(imgs_path/'picture.png'))\n",
    "PIL.Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # Pillow expects a RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = convert_bgr_to_grayscale(img)\n",
    "PIL.Image.fromarray(gray_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe861d6",
   "metadata": {},
   "source": [
    "## Histogram of the pixels values in the image\n",
    "\n",
    "We may analyze the illumination by the distribution of the pixel values in the image, i.e. by its histogram. In general, this is only applied to each color channel separately, or to the image in grayscale.\n",
    "\n",
    "Therefore, let us build an histogram. We need to count how many pixels we have of each value. For 8 bits images, the values range from 0 to 255 (inclusive).\n",
    "\n",
    "Implement the following function to return a count of pixel values of an image composed by a single color channel (1 point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa984ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52401227f2c9a4ca1c7e8749eb26d2be",
     "grade": false,
     "grade_id": "hist",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram(mono_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a histogram of the image, by counting how many pixels exist of a given value.\n",
    "    :param mono_img: matrix (H, W) which represents an image of height H and width W.\n",
    "    :return: an array (v) with the counting (q) of the pixel values (i) in the image, such that v[i] = q.\n",
    "    \"\"\"\n",
    "    counts = np.zeros(256, dtype=np.uint64)\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0931b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6fccda6b379d1756909991e430482ab",
     "grade": true,
     "grade_id": "testa_hist",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(str(imgs_path/'picture.png'))\n",
    "green_channel = img[:, :, 1]\n",
    "hist = histogram(green_channel)\n",
    "assert np.all(hist ==\n",
    "      [   0,    0,    0,   11,   65,  111,  164,  261,  308,  431,  537,\n",
    "        682,  846,  912, 1074, 1350, 1480, 1681, 1621, 2064, 1835, 2048,\n",
    "       1989, 1911, 2258, 2129, 1748, 1776, 1850, 1687, 1605, 1661, 1355,\n",
    "       1360, 1189, 1278, 1062, 1027, 1052, 1084, 1013, 1026,  915,  926,\n",
    "       1029, 1013, 1023,  875, 1110, 1057,  862, 1120,  927, 1073, 1069,\n",
    "       1004, 1275, 1274, 1129, 1266, 1495, 1548, 1591, 2046, 1706, 1998,\n",
    "       1704, 2022, 1705, 1800, 1674, 1766, 1593, 1711, 1474, 1491, 1566,\n",
    "       1456, 1445, 1524, 1371, 1545, 1278, 1606, 1364, 1475, 1513, 1537,\n",
    "       1813, 1863, 1681, 1885, 2170, 1907, 2008, 1948, 2325, 2094, 1713,\n",
    "       2084, 1670, 1811, 1720, 1743, 1603, 1693, 1386, 1515, 1639, 1542,\n",
    "       1588, 1540, 1784, 1751, 1425, 1836, 1604, 1565, 1581, 1507, 1762,\n",
    "       1769, 1448, 1654, 1872, 1914, 1844, 2103, 1925, 2023, 1811, 2206,\n",
    "       1907, 1968, 2026, 2096, 2032, 2029, 1730, 1607, 1666, 1454, 1341,\n",
    "       1354, 1247, 1213,  942, 1152,  931, 1080,  981,  904, 1006, 1003,\n",
    "        814,  779,  848,  817,  756,  828,  690,  696,  579,  622,  514,\n",
    "        528,  499,  506,  450,  504,  414,  483,  504,  473,  474,  452,\n",
    "        621,  587,  512,  611,  652,  723,  645,  656,  850,  777,  720,\n",
    "        719,  812,  741,  646,  703,  778,  767,  611,  800,  699,  795,\n",
    "        781,  830,  816,  912,  843,  851,  847,  788,  687,  700,  573,\n",
    "        499,  377,  388,  288,  294,  241,  201,  168,  167,  125,  114,\n",
    "        102,  108,   68,   57,   54,   49,   16,   18,   10,    7,    5,\n",
    "          9,    2,    1,    1,    0,    2,    0,    0,    0,    0,    0,\n",
    "          1,    0,    0,    2,    0,    0,    1,    0,    0,    0,    0,\n",
    "          0,    0,    0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef654bc",
   "metadata": {},
   "source": [
    "Plot of the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(256), hist, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec7985",
   "metadata": {},
   "source": [
    "`matplotlib` also has the method `plt.hist` which computes the histogram of an array. To use this function, we need to convert the image matrix into a 1D array using `matrix.ravel()` or `.flatten()`. Moreover, the `matplotlib`'s method also receives the number of bins used to plot the histogram as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gray_img.ravel(), bins=np.arange(256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b1381",
   "metadata": {},
   "source": [
    "## Additive and multiplicative gains\n",
    "\n",
    "For each pixel $I[y, x]$, we will apply an affine transform composed of additive and multiplicative gains: $I_{r}[y, x] = \\alpha \\cdot I[y, x] + \\beta$. Furthermore, the value is clipped so it stays within the interval $[0, 255]$.\n",
    "\n",
    "Implement this operation in the following cell (1 point).\n",
    "\n",
    "The function `cv2.convertScaleAbs(image, alpha, beta)` from OpenCV does the same operation. However, **you are not allowed to use this function**.\n",
    "\n",
    "<details><summary><b>Hints (click to expand):</b></summary>\n",
    "    \n",
    "When needed, use `matrix.astype(np.float64)` / `np.uint8` to convert NumPy matrices to `float64` / `uint8`. Also, use `np.clip` to limit the values to stay within 0 to 255.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe07849",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d623b03bb712c004903be7606d843b6b",
     "grade": false,
     "grade_id": "ganho",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gain(img: np.ndarray, alpha: float, beta: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function implements an affine transform composed of additive and multiplicative gains following:\n",
    "    Ir[y, x] = alpha * I[y, x] + beta.\n",
    "    Moreover, the value is clipped to stay within the interval [0, 255].\n",
    "    :param img: matrix (H, W) or (H, W, C) which represents an image with height H, width W, and C color channels.\n",
    "    :param alpha: multiplicative gain.\n",
    "    :param beta: additive gain.\n",
    "    :return: the transformed image.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68761a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9dac5549811c286a9b5a625daa08e8b",
     "grade": true,
     "grade_id": "testa_ganho",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(gain(np.ones((9, 9), dtype=np.uint8), 30, 50) == 80)\n",
    "assert gain(np.ones((9, 9), dtype=np.uint8), 180, 160).dtype == np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505d46f",
   "metadata": {},
   "source": [
    "We will now apply this function to improve the performance of an OCR algorithm in the case the image has been captured in a place with low illumination (1 point). Actually, to simulate this effect, we will apply a gain to attenuate the image.\n",
    "\n",
    "<details><summary><b>Hints (click to expand):</b></summary>\n",
    "See the histogram of the image.\n",
    "\n",
    "Apply a gain to make the background color close to white. See the results in the cells below. Internally, Tesseract does already use a dynamic threshold for binarization using the Otsu's method.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501588e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8eec57bd0d87fb7f8e7a0738748f5c82",
     "grade": false,
     "grade_id": "recupera_escuro",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recover_dark_image(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a gain transform to recover a dark image of a container plane.\n",
    "    :param img: matrix (H, W) or (H, W, C) which represents an image of height H, width W, and C color channels.\n",
    "    :return: a recovered image, where it is possible to visualize the characters of the plate.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return recovered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fbbb7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c5cc8205e72d6738c3f7515948d1f0",
     "grade": true,
     "grade_id": "testa_recupera_escuro",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dark_plate = cv2.imread(str(imgs_path/'placa_escura.png'))\n",
    "recovered_plate = recover_dark_image(dark_plate)\n",
    "assert ocr(recovered_plate) == 'APZU 345314 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e3c40",
   "metadata": {},
   "source": [
    "Notice how some characteres are hardly visible by human eyes in the low illumination condition, but become very visible after the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ea989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(dark_plate))\n",
    "PIL.Image.fromarray(dark_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(recovered_plate))\n",
    "PIL.Image.fromarray(recovered_plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47573382",
   "metadata": {},
   "source": [
    "The function `cv2.equivalizeHist` from OpenCV also permits equalizing the distribution of the values in an image. This function tries to mantain the histogram approximately constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6939454",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.fromarray(cv2.equalizeHist(dark_plate[:,:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b5b78",
   "metadata": {},
   "source": [
    "## Borders\n",
    "\n",
    "As explained in class, when we use cross correlation or convolution, we may need to add pixels to the borders so we can apply the kernel on the borders. In our case of identifying letters in a plate, we may have difficulty with letters close to the image borders due to this issue.\n",
    "\n",
    "We will now implement a function to add pixels to the borders of an image (also called padding) (0.5 points).\n",
    "\n",
    "<details><summary><b>Hints (click to expand):</b></summary>\n",
    "    \n",
    "When indexing arrays in NumPy, use `matrix[start0:stop0, start1:stop1, start2:stop2]`.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e5b39",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19dead162a220885ac443f8d8ed2a2b2",
     "grade": false,
     "grade_id": "bordas",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def padding(image: np.ndarray, border_color: tuple, padding: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add padding to an image.\n",
    "    :param image: matrix (H, W, C) which represents an image of height H, width W, and C color channels.\n",
    "    :param border_color: tuple (C1, C2, C3, ...) which represents a color that can be applied to a border.\n",
    "    :param padding: tuple (left, right, top, bottom) which represents the amount of pixels to be added\n",
    "                    to each border.\n",
    "    :return: the image after padding.\n",
    "    \"\"\"\n",
    "    h0, w0, c = image.shape\n",
    "    left, right, top, bottom = padding\n",
    "    padded_image = np.zeros((h0 + top + bottom, w0 + left + right, c), dtype=np.uint8)\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510339ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f558fd2f85f554065357e03daffa88ee",
     "grade": true,
     "grade_id": "teste_bordas",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img = np.arange(20, dtype=np.uint8).reshape(4, 5, 1)\n",
    "assert np.all(padding(img, (0, ), (2, 2, 1, 1))[:, :, 0] == np.array(\n",
    "      [[ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "       [ 0,  0,  0,  1,  2,  3,  4,  0,  0],\n",
    "       [ 0,  0,  5,  6,  7,  8,  9,  0,  0],\n",
    "       [ 0,  0, 10, 11, 12, 13, 14,  0,  0],\n",
    "       [ 0,  0, 15, 16, 17, 18, 19,  0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf65a5",
   "metadata": {},
   "source": [
    "Now, let us add padding to a plate image to help the OCR algorithm (0.5 points).\n",
    "Since the image background is white, we should add white pixels during padding. Moreover, adding 4 pixels on each border should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1c4d1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0be7aeb80e6dcbc409c5290ffa318eed",
     "grade": false,
     "grade_id": "recupera_borda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plate_padding(image):\n",
    "    \"\"\"\n",
    "    Adds padding to a plate image so the OCR method can correctly identify the characters.\n",
    "    :param image: matrix (H, W, 3) which represents an image of height H, width W, and 3 color channels.\n",
    "    :return: an image where characters close to the borders are recognizable by the OCR method.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75899382",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99f99c990f971f938e516aadfe9dc6e0",
     "grade": true,
     "grade_id": "testa_recupera_borda",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cropped_plate = cv2.imread(str(imgs_path/'placa_cortada.png'))\n",
    "padded_plate = plate_padding(cropped_plate)\n",
    "assert ocr(padded_plate) == 'HLBU 305874 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbee89b",
   "metadata": {},
   "source": [
    "Notice that some characters are identified correctly in the cropped plate, but after adding padding, all of them are correctly identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1347e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(cropped_plate))\n",
    "PIL.Image.fromarray(cropped_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d492f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(padded_plate))\n",
    "PIL.Image.fromarray(padded_plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d3bd2",
   "metadata": {},
   "source": [
    "## Cross Correlation and Convolução\n",
    "\n",
    "In the class, we discussed about the differences between cross correlation and convolution. Since many computer vision implement cross correlation instead of convolution to apply filters, we will implement cross correlation here. As explained in class, the diferrence is not very relevant, because we use cross correlation to do convolution just by flipping the kernel horizontally and vertically.nais. Na realidade, na implementação abaixo, é da operação matemática equivalente a correlação cruzada, uma vez que o kernel não está invertido.\n",
    "\n",
    "The cross correlation operation is defined by the following equation:\n",
    "\n",
    "$G[i, j] = \\sum^k_{u=-k} \\sum^k_{v=-k} H[u, v] I[i + u, j + v]$\n",
    "\n",
    "Implement the cross correlation function below (2 points).\n",
    "\n",
    "\n",
    "<details><summary><b>Hints (click to expand):</b></summary>\n",
    "\n",
    "- Use the following array indexing from NumPy: `matrix[start0:stop0, start1:stop1, start2:stop2]`. \n",
    "    \n",
    "- Use element-wise multiplication through the operator `*`.\n",
    "    \n",
    "- Use `np.sum` to sum the elements of an array.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6846fe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27f63f242dad199b5cdc8c5784eb86d",
     "grade": false,
     "grade_id": "conv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_correlation(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Executes cross correlation of an image using a filter (kernel or mask).\n",
    "    :param image: matrix (H, W) which represents an image of height H and width W.\n",
    "    :param kernel: matrix (Hf, Wf) which represents a filter (kernel or mask) of height Hf and width Wf.\n",
    "    :return: the result of the cross correlation between the image and the filter.\n",
    "    \"\"\"\n",
    "    h0, w0 = image.shape\n",
    "    hf, wf = kernel.shape\n",
    "    output = np.zeros((h0 - hf + 1, w0 - wf + 1), dtype=np.float64)\n",
    "    for i in range(h0 - hf + 1):\n",
    "        for j in range(w0 - wf + 1):\n",
    "            # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "            raise NotImplementedError()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167cb9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6668c4a18126ef649203f1876dc44ba3",
     "grade": true,
     "grade_id": "testa_conv",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(cross_correlation(\n",
    "    np.array([[1, 1, 1, 0, 0],\n",
    "              [0, 1, 1, 1, 0],\n",
    "              [0, 0, 1, 1, 1],\n",
    "              [0, 0, 1, 1, 0],\n",
    "              [0, 1, 1, 0, 0]]), \n",
    "    np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]])) == np.array([[4, 3, 4],\n",
    "                                        [2, 4, 3],\n",
    "                                        [2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69c291",
   "metadata": {},
   "source": [
    "A cross correlation with a given filter (kernel) may implement a known mathematical operation. For example, the Sobel filter implements a partial derivate of the image through finite difference. The Sobel filter for computing the $x$ partial derivative of the image is given by: \n",
    "\n",
    "$\\mathbf {S} _{x}={\\begin{bmatrix}+1&0&-1\\\\+2&0&-2\\\\+1&0&-1\\end{bmatrix}}$\n",
    "\n",
    "The following cell computes the $x$ partial derivative of the Lena's image in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65760a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([[1, 0, -1],\n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]])\n",
    "gray_img_dx = cross_correlation(gray_img, sobel_x)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(gray_img_dx, cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab476",
   "metadata": {},
   "source": [
    "## Gaussian Filter\n",
    "\n",
    "The Gaussian filter is frequently used to blue images or attenuate noise. The kernel of the Gaussian filter is a discrete approximation of the 2D Gaussian function:\n",
    "\n",
    "$H(x, j) = \\frac{1}{2 \\pi \\sigma^2} \\exp \\left( -\\frac{(x - x_0)^2 + (y - y_0)^2}{2 \\sigma^2} \\right)$.\n",
    "\n",
    "The discrete approximation is computed as:\n",
    "\n",
    "$H[u, v] = \\alpha  \\exp \\left( \\frac{-(u-u_0)^2 + (v-v_0)^2}{2 \\sigma^2} \\right)$,\n",
    "\n",
    "where $\\alpha$ is a normalization constant so the kernel's values sum to 1 and $\\sigma$ is a design parameter.\n",
    "\n",
    "This is the best classic filter to attenuate Gaussian noise. It can also be interpreted as a low-pass filter that attenuates high frequencies. Using a Fourier transform, we can verify that this filter attenuates high frequencies.\n",
    "\n",
    "Implement the function that computes the Gaussian kernel of dimension $(k, k)$ below, using the terms $u_0 = \\frac{k-1}{2}$ e $v_0 = \\frac{k-1}{2}$ so the Gaussian function stays at the center of the kernel (1 point).\n",
    "\n",
    "**You are not allowed to use OpenCV to do this implementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7d0ef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a39bd8bf954f416a281ef54bc9d5ae6",
     "grade": false,
     "grade_id": "gauss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_gaussian_kernel(k, sigma):\n",
    "    \"\"\"\n",
    "    Builds a Gaussian kernel of size k and standard deviation sigma.\n",
    "    :param k: kernel size.\n",
    "    :param sigma: standard deviation. \n",
    "    Retorna o kernel gaussiano normalizado, matriz float de tamanho (k, k) tipo float64\n",
    "    \"\"\"\n",
    "    kernel = np.zeros((k, k), dtype=np.float64)\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15c569",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc235c26972a5bd2a80df81414c5bea1",
     "grade": true,
     "grade_id": "testa_gauss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.linalg.norm(build_gaussian_kernel(3, 1) - np.array(\n",
    "      [[0.07511361, 0.1238414 , 0.07511361],\n",
    "       [0.1238414 , 0.20417996, 0.1238414 ],\n",
    "       [0.07511361, 0.1238414 , 0.07511361]])) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba383c02",
   "metadata": {},
   "source": [
    "Let the effect of this kernel on the image below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d436eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cross_correlation(gray_img, build_gaussian_kernel(7, 5))\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(blurred_img, cmap='gray')\n",
    "plt.plot()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(blurred_img[350:500, 100:250], cmap='gray', interpolation='nearest')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d08e2",
   "metadata": {},
   "source": [
    "As seen in class, a simpler filter consider only the arithmetic average. However, this filter adds a high frequency component, which creates undesired artifacts, as we can see in the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c77883",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img_box = cross_correlation(gray_img, np.ones(25).reshape(5,5)/25)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(blurred_img_box, cmap='gray')\n",
    "plt.plot()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(blurred_img_box[350:500, 100:250], cmap='gray', interpolation='nearest')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8409692",
   "metadata": {},
   "source": [
    "We can also create a filter to unblur (sharpen) an image. The idea behind this filter is to amplify the image and subtract its filtered version, so the variations in the image are amplified.\n",
    "\n",
    "In the following cell, we use a sharpen kernel to sharpen the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475aec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_kernel = np.zeros((5, 5))\n",
    "identity_kernel[2, 2] = 1\n",
    "sharpen_kernel = 4 * identity_kernel - 3 * np.ones((5, 5)) / (5 * 5)\n",
    "print('Sharpen Kernel:')\n",
    "print(sharpen_kernel)\n",
    "sharpened_img = cross_correlation(blurred_img, sharpen_kernel)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(blurred_img, cmap='gray')\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(sharpened_img, cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e344b90",
   "metadata": {},
   "source": [
    "OpenCV has these functions already implemented:\n",
    "- `cv2.GaussianBlur`: blurs an image using a Gaussian filter.\n",
    "- `cv2.blur`: blurs an image using a box filter (arithmetic average).\n",
    "- `cv2.medianBlur`: blurs an image using a median filter.\n",
    "- `cv2.filter2D`: applies a kernel to an image using cross correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096e209",
   "metadata": {},
   "source": [
    "## Noise\n",
    "\n",
    "Gaussian noise is related especially to the sampling of incident photons on the image sensors, and to the spurious photons coming from the black body radiation.\n",
    "\n",
    "The classical filter that best attenuates Gaussian noise is the Gaussian filter.\n",
    "\n",
    "For each pixel, a random variable following a Gaussian distribution is added to the pixel value:\n",
    "\n",
    "$I'[i,j] = I[i,j] + \\eta[i,j]$,\n",
    "\n",
    "where $\\eta[i,j] \\sim N(0,\\sigma^2)$.\n",
    "\n",
    "Implement the function below which applies a Gaussian filter to the image to allow the OCR to identify the characters in the plate (1 point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78103f21",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6495f44003bbf84444134379395d0885",
     "grade": false,
     "grade_id": "ruido",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_noise_plate(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies a Gaussian filter in a plate's image so the OCR is able to identify the characters. Uses the cross correlation\n",
    "    function with a Gaussian filter.\n",
    "    :param image: matrix (H, W) which represents an image with height H and width W.\n",
    "    :return: filtered image so the characters are  identifiable by the OCR.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32469ef3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d8031c29168579f19d49cbe1bf00ba",
     "grade": true,
     "grade_id": "testa_ruido",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "noisy_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_ruido.png')))\n",
    "filtered_plate = filter_noise_plate(noisy_plate)\n",
    "assert ocr(filtered_plate) == 'MEDU 297781 3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89492e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(noisy_plate))\n",
    "PIL.Image.fromarray(noisy_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f30f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(filtered_plate))\n",
    "PIL.Image.fromarray(filtered_plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f108c1",
   "metadata": {},
   "source": [
    "## Morphological Operations\n",
    "\n",
    "Morphological operations are similar to cross correlation with a kernel, since we slide a window through the image. However, the operations are nonlinear. For example, the morphological operations of dilatation and erosion choose the maximum and minimum of the window, respectively. These operations are implemented in OpenCV by `cv2.dilate` and `cv2.erode`, respectively.\n",
    "\n",
    "![Dilatação](https://penny-xu.github.io/dialate-d6ec2fc1995eeeb95b917db2c6e1cea0.gif)\n",
    "\n",
    "The morphological operations are defined for binary images. Nevertheless, we can also generalize them for grayscale (maximum/minimum element of a window).\n",
    "\n",
    "Moreover, to binarize Lena's image below, we use a thredhold of 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9118dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_img = 255 * (gray_img > 120).astype(np.uint8)\n",
    "PIL.Image.fromarray(binary_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1a49e",
   "metadata": {},
   "source": [
    "The following images help visualize what the dilatation and erosion operations do to an image. Notice that dilatation and erosion work on the white pixels, i.e. dilation dilatates the white pixels while erosion erodes the white pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "structuring_element = np.ones((3, 3))\n",
    "dillated_img = cv2.dilate(binary_img, structuring_element)\n",
    "PIL.Image.fromarray(dillated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "structuring_element = np.ones((3, 3))\n",
    "eroded_img = cv2.erode(binary_img, structuring_element)\n",
    "PIL.Image.fromarray(eroded_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600cb64",
   "metadata": {},
   "source": [
    "In the next code cell, implement a morphological operation to recover the following plate so the OCR is able to better detect the characters (1 point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faint_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_erodida.png')))\n",
    "print(ocr(faint_plate))\n",
    "PIL.Image.fromarray(faint_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfcd17",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ee0c80bd539306ee56f7b806e6456f6",
     "grade": false,
     "grade_id": "dilatacao",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def morphological_operation_plate(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Executes a morphological operation to recover the plate.\n",
    "    :param image: matrix (H, W) which represents an image of height H and width W.\n",
    "    :return: image after morphological operation that allows the identification of the characters through OCR.\n",
    "    \"\"\"\n",
    "    structuring_element = np.ones((3, 3))\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b00334",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a8e541fd5fd5dd958b253fb9e93ae8f",
     "grade": true,
     "grade_id": "testa_dilatacao",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "faint_plate = convert_bgr_to_grayscale(cv2.imread(str(imgs_path/'placa_erodida.png')))\n",
    "recovered_plate = morphological_operation_plate(faint_plate)\n",
    "assert ocr(recovered_plate) == 'APZU 345314 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b64f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(recovered_plate))\n",
    "PIL.Image.fromarray(recovered_plate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566a546",
   "metadata": {},
   "source": [
    "There are many other image processing methods that we can apply to an image. For example, to rotate/scale/translate/shear an image, we can use `cv2.warpAffine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0579bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(imgs_path/'picture.png'))\n",
    "transform = cv2.getRotationMatrix2D((350, 250), 70, 1.4)\n",
    "rotated_img = cv2.warpAffine(img, transform, (700, 700))\n",
    "PIL.Image.fromarray(cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7352eb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73f63956",
   "metadata": {},
   "source": [
    "# Your data and feedback:\n",
    "\n",
    "Write a feedback for the lab so we can make it better for the next years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09875c",
   "metadata": {},
   "source": [
    "In the following variables, write the number of hours spent on this lab, the perceived difficulty, and the expected grade (you may delete the `raise` and the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9e6d5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f613d80a345c28aaf937672ec9e9f5",
     "grade": true,
     "grade_id": "meta_eval",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# meta_eval manual_graded_answer 0\n",
    "\n",
    "horas_gastas = None    # 1.5   - Float number with the number of hours spent \n",
    "dificuldade_lab = None # 0     - Float number from 0.0 to 10.0 (inclusive)\n",
    "nota_esperada = None   # 10    - Float number from 0.0 to 10.0 (inclusive)\n",
    "\n",
    "# WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5dc11",
   "metadata": {},
   "source": [
    "Write below other comments or feedbacks about the lab. If you did not understand anything about the lab, please also comment here.\n",
    "\n",
    "If you find any typo or bug in the lab, please comment below so we can fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a7580",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc6431aff9a971fe5ed82c62bc668c96",
     "grade": true,
     "grade_id": "meta_eval_discursivo",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "WRITE YOUR SOLUTION HERE! (do not change this first line):\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**DISCURSIVE QUESTION**\n",
    "\n",
    "WRITE YOUR ANSWER HERE (do not delete this cell so the ID is not lost)\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80ba32",
   "metadata": {},
   "source": [
    "**End of the lab!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
