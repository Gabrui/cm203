{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6181190",
   "metadata": {},
   "source": [
    "**Aeronautics Institute of Technology ‚Äì ITA**\n",
    "\n",
    "**Computer Vision ‚Äì CM-203**\n",
    "\n",
    "**Professors:** \n",
    "\n",
    "Marcos Ricardo Omena de Albuquerque Maximo\n",
    "\n",
    "Gabriel Adriano de Melo\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "Before submitting your lab, be sure that everything is running correctly (in sequence): first, **restart the kernel** (`Runtime->Restart Runtime` in Colab or `Kernel->Restart` in Jupyter). Then, execute all cells (`Runtime->Run All` in Colab or `Cell->Run All` in Jupyter) and verifies that all cells run without any errors, expecially the automatic grading ones, i.e. the ones with `assert`s.\n",
    "\n",
    "**Do not delete the answer cells**, i.e. the ones that contains `WRITE YOUR CODE HERE` or `WRITE YOUR ANSWER HERE`, because they contain metadata with the ids of the cells for the grading system. For the same reason, **do not delete the test cells**, i.e. the ones with `assert`s. The autograding system executes all the code sequentially, adding extra tests in the test cells. There is no problem in creating new cells, as long as you do not delete answer or test cells. Moreover, keep your solutions within the reserved spaces.\n",
    "\n",
    "The notebooks are implemented to be compatible with Google Colab, and they install the dependencies and download the datasets automatically. The commands which start with ! (exclamation mark) are bash commands and can be executed in a Linux terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fc055",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933cf448",
   "metadata": {},
   "source": [
    "# Laborat√≥rio 6 - nanoYOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e24cc1",
   "metadata": {},
   "source": [
    "Neste laborat√≥rio iremos explorar os principais passos necess√°rios na detec√ß√£o de objetos, sobretudo de m√©todos de um √∫nico est√°gio, especificamente do YOLO proposta pelo [Joseph Redmon](https://pjreddie.com/darknet/yolo/), em suas vers√µes iniciais. Algo essencial para voc√™s entenderem √© o processo de tornar sa√≠das aparentemente gen√©ricas, cont√≠nuas, de tamanhos n√£o definidos, em estruturas discretas que aproximam o valor gen√©rico. Sobretudo que a implementa√ß√£o deste lab √© apenas uma forma, apenas uma realiza√ß√£o dentre as muitas poss√≠veis.\n",
    "\n",
    "Assim, o nosso primeiro passo ser√° transformar uma lista de *bounding boxes* em um tensor de tamanho bem definido, que √© justamente a sa√≠da esperada da rede, o $y$ a ser comparado com o $\\hat{y}$ da rede. O segundo passo realizar um transfer learning a partir da arquitetura de uma rede de classifica√ß√£o de objetos, iso √©, iremos modificar as √∫ltimas camadas de sua arquitetura para termos a estrutura desejada. Em seguida iremos definir a fun√ß√£o custo que √© simplesmente a combina√ß√£o de v√°rias outras fun√ß√µes. Finalmente, iremos aplicar a supress√£o n√£o-maximal da sa√≠da da rede para obter uma lista de *bounding boxes* que se aproxime da nossa lista inicial do treino.\n",
    "\n",
    "Aten√ß√£o, as implementa√ß√µes desse lab s√£o simplificadas em compara√ß√£o √† literatura, pois o objetivo do lab √© ensinar a ess√™ncia, o b√°sico, a intui√ß√£o, os elementos fundamentais. Para uma aplica√ß√£o no mundo real, utilize modelos e arquiteturas estado-da-arte consagrados <sub><sup>pelos sacerdotes do Deep Learning</sub></sup>.\n",
    "\n",
    "Trivia: YOLO, *You Only Look Once*, nome da arquitetura de rede neural convolucional √© inspirada pela g√≠ria ingl√™s *You Only Live Once*, utilizada geralmente quando algu√©m vai fazer alguma a√ß√£o perigosa ou [alguma besteira](https://www.youtube.com/watch?v=dh6RB1RT9i0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd56b6",
   "metadata": {},
   "source": [
    "## Imports and data downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze | grep 'timm' || pip3 install -Uqq datasets==2.14.5 timm==0.9.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9c97b",
   "metadata": {},
   "source": [
    "Todos os nossos imports ser√£o realizados automaticamente pela FastAI. Enquanto ma maior parte das bibliotecas pode ser uma m√° ideia utilizar um star import (`*`) pois ir√° poluir o seu ambiente, o FastAI toma cuidado de limitar o que √© exportado (importado pelo `*`) por meio da defini√ß√£o da vari√°vel `__all__` dentro de um m√≥dulo. Assim, tudo que √© exportado/importado por ele √© intencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.patches as patches\n",
    "from timm.models.layers import trunc_normal_, DropPath\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f04a2f",
   "metadata": {},
   "source": [
    "Aten√ß√£o, se por algum motivo voc√™ for mudar a pasta `/content` ou a flag de `RETRAIN`, mude na c√©lula abaixo, pois ela √© sobrescrita durante a corre√ß√£o (*read_only*) uma vez que para a corre√ß√£o funcionar o `base_path` tem que apontar para a pasta correta. Durante a corre√ß√£o, o `RETRAIN` ser√° `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f7555",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc29e0fed171f7711c6d92edde03cd8b",
     "grade": false,
     "grade_id": "dataset_lab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# dataset_lab read_only\n",
    "\n",
    "! [ ! -d \"/content/nanoyolo\" ] && gdown -O /content/nanoyolo.zip \"1H2w5WANOzmnn7OawBNAUtr0vhYb0e8P8\" &&  unzip -q /content/nanoyolo.zip -d /content && rm /content/nanoyolo.zip\n",
    "! [ ! -d \"/content/nanoyolo\" ] && wget -P /content/ \"http://ia.gam.dev/cm203/23/lab06/nanoyolo.zip\"  &&  unzip -q /content/nanoyolo.zip -d /content && rm /content/nanoyolo.zip\n",
    "base_path = Path(\"/content/nanoyolo\")\n",
    "%cd /content\n",
    "\n",
    "RETRAIN = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa021d",
   "metadata": {},
   "source": [
    "E agora vamos baixar o dataset de detec√ß√£o de terroristas e contra-terroristas do CS-GO! Estamos utilizando o [HuggingFace](https://huggingface.co/) ü§ó como reposit√≥rio dos dados. Al√©m dos dados, na realidade, ele √© um dos maiores reposit√≥rios de redes neurais do mundo, disponibilizando os pesos das redes gratuitamente e de forma aberta. Ele tamb√©m tem a sua pr√≥pria biblioteca baseado no PyTorch e que lembra o FastAI, justamente por ter sido um dos seus fundadores, o Sylvain Gugger, o coautor que ajudou o Jeremy Howard a desenvolver a biblioteca do FastAI e escrever o livro e o curso.\n",
    "\n",
    "Outra refer√™ncia importante para a vida, √© o [Papers With Code](https://paperswithcode.com/) onde os pesquisadores que escrevem artigos, principalmente pre-prints do arXiv, juntamente com a comunidade acad√™mica e da ind√∫stria indexam os trabalhos mais relevantes em conjunto com a suas implementa√ß√µes no GitHub.\n",
    "\n",
    "Devida √† natureza altamente r√°pida do desenvolvimento de IA, a maior parte dos pesquisadores usam confer√™ncias em vez de journals para a publica√ß√£o de seus trabalhos, mas antes disso ainda, o usual √© publicar um pr√©-print no arXiv e espalhar o seu trabalho na comunidade, principalmente atrav√©s do Twitter, onde naturalmente os artigos mais relevantes tendem a ser compartilhado mais frequentemente pela comunidade. Os principais pesquisadores, como [Yann LeCun](https://twitter.com/ylecun), o [Geoffrey Hinton](https://twitter.com/geoffreyhinton), o [Jeremy Howard](https://twitter.com/jeremyphoward), o [Sylvain Gugger](https://twitter.com/GuggerSylvain), o [Ilya Sutskever](https://twitter.com/ilyasut), o [Andrej Karpathy](https://twitter.com/karpathy), o . Eu tamb√©m tenho minha conta no Twitter, [Gabriel A. Melo](https://twitter.com/gabruio), ainda n√£o tenho nenhuma publica√ß√£o relevante, mas pelo menos eu tento seguir os principais pesquisadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dataset = load_dataset(\"keremberke/csgo-object-detection\", name=\"full\").sort('image_id') # keep_in_memory=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f3502",
   "metadata": {},
   "source": [
    "O bom dessa biblioteca √© que em vez de armazenar as imagens como arquivos separados, ela utiliza uma estrutura de banco de dados (Apache Parquet), que diminui o overhead de ler v√°rios arquivos pequenos. A forma como ele disponibiliza esses dados √© de um dicion√°rio especial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c7dd5e",
   "metadata": {},
   "source": [
    "Que n√≥s podemos acessar tal qual um `dict` normal, observe que o `bbox` √© uma lista de *tuplas* (na verdade s√£o listas de tamanhos fixos) de 4 elementos onde cada tupla representa uma *bounding box* por meio da sua aresta $(x_0, y_0, w, h)$ do canto superior esquerdo $(x_0, y_0)$ e de sua altura e largura $(w, h)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a556a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dado_treino_0 = cs_dataset['train'][1052]\n",
    "dado_treino_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e11bbe",
   "metadata": {},
   "source": [
    "E tamb√©m vamos definir os nomes das classes, isto √©, cada n√∫mero inteiro do `category` na realidade est√° associado a um desses nomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_classes = ['Contra-Terrorista', 'Cabe√ßa CT', 'Terrorista', 'Cabe√ßa Terrorista']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea696d",
   "metadata": {},
   "source": [
    "Observe a primeira imagem com as suas respectivas bounding boxes desenhadas (reza a lenda que o c√≥digo de plot tem parte da resposta da pr√≥xima quest√£o):\n",
    "\n",
    "\n",
    "*(n√£o precisa entender o c√≥digo abaixo)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcfbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dado(dado, desenha_bb=True, desenha_centros=False, grid=0):\n",
    "    fig, ax = plt.subplots(dpi=100)\n",
    "    ax.imshow(dado['image'])\n",
    "    if grid:\n",
    "        width, height = dado['image'].size\n",
    "        ax.set_xticks(np.arange(0, width, grid))\n",
    "        ax.set_yticks(np.arange(0, height, grid))\n",
    "        ax.grid(True)\n",
    "    else:\n",
    "        ax.set_axis_off()\n",
    "    if not desenha_bb:\n",
    "        return\n",
    "    cores = ['green', 'blue', 'red', 'pink']\n",
    "    for bbox, cate in zip(dado['objects']['bbox'], dado['objects']['category']):\n",
    "        x_vertice, y_vertice, largura, altura = bbox\n",
    "        ax.add_patch(patches.Rectangle((x_vertice, y_vertice), largura, altura, linewidth=2, edgecolor=cores[cate], facecolor='none'))\n",
    "        ax.text(x_vertice, y_vertice, nomes_classes[cate], c=cores[cate])\n",
    "        if desenha_centros:\n",
    "            plt.plot(x_vertice+largura/2, y_vertice+altura/2, color=cores[cate], marker='x')\n",
    "\n",
    "plot_dado(dado_treino_0, grid=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16884200",
   "metadata": {},
   "source": [
    "## Montando o tensor de Sa√≠da Verdadeira (2 pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa93e1",
   "metadata": {},
   "source": [
    "**Explica√ß√£o sobre o assunto**\n",
    "\n",
    "Uma das grandes sacadas na detec√ß√£o de objetos baseadas em um √∫nico est√°gio √© justamente como definir um tensor de sa√≠da que tenha dimens√µes fixas (na realidade em fun√ß√£o do tamanho da imagem), sendo que a nossa sa√≠da na realidade √© uma lista de *bounding boxes* (BBs).\n",
    "\n",
    "A primeira tentativa seria simplesmente limitar o tamanho m√°ximo dessa lista, indicando com uma flag se o √≠ndice est√° vazio ou n√£o. Mas se f√¥ssemos fazer isso n√≥s ter√≠amos um outro problema (que √© at√© mais dif√≠cil), que √© a ordena√ß√£o dos elementos dessa lista, que precisaria seguir uma regra bem definida e consistente, pois se n√£o estar√≠amos penalizando a rede aleatoriamente pela ordem da sa√≠da que ela gera. Acontece que tanto definir fazer com que a rede aprende tal mecanismo de orderna√ß√£o n√£o √© t√£o f√°cil quanto parece ...\n",
    "\n",
    "Isso se torna evidente quanto temos muitas bounding boxes em uma mesma imagem, veja o exemplo abaixo (com 18 BBs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo_muitos = cs_dataset['train'][1807]\n",
    "exemplo_muitos['objects']['bbox'], exemplo_muitos['objects']['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7d779",
   "metadata": {},
   "source": [
    "Olhe a imagem abaixo e tente localizar os terroristas e os contra-terroristas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97567337",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dado(exemplo_muitos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2a20f",
   "metadata": {},
   "source": [
    "Outra solu√ß√£o ainda nessa linha seria simplesmente encontrar uma permuta√ß√£o dos elementos dessa lista que minimize a penaliza√ß√£o (o dano, o gradiente) que iremos causar na rede, assim n√£o precisar√≠amos nos preocupar com a ordem. A dificuldade agora est√° justamente em fazer esse match, que se torna cada vez mais dif√≠cil ($n^2$) com o aumento do tamanho m√°ximo $n$ dessa lista.\n",
    "\n",
    "Mas a solu√ß√£o natural √© aproveitar a pr√≥pria estrutura 2d espacial da imagem (entrada) e da sa√≠da (bounding boxes) para termos, enfiom, uma estrutura de tamanho bem definido sem se preocupar com ordena√ß√£o, que na realidade j√° vem de gra√ßa pelas pr√≥prias dimens√µes espaciais! Isto √©, associamos as bounding boxes a um grid espacial.\n",
    "\n",
    "Observe o grid abaixo da YOLOv1, sendo que agora s√≥ temos uma √∫nica bounding box associada a cada posi√ß√£o do grid.\n",
    "\n",
    "![YOLO tensor](https://www.researchgate.net/profile/Cedric_Perauer/publication/349929458/figure/fig7/AS:999598260768778@1615334205592/YOLOv4-output-tensor-29-The-width-and-height-depend-on-the-size-of-the-head_W640.jpg)\n",
    "\n",
    "Ent√£o no final das contas, √© como se estiv√©ssemos transformando uma imagem de entrada RGB $(3, H, W)$ de altura $H$ e largura $W$ em uma outra *imagenzinha* de sa√≠da $(1 + 4 + C, h_g, w_g)$ que tem dimens√µes espaciais (largura $w_g$ e altura $h_g$) muito menores, mas com dimens√µes de informa√ß√£o adicionais sendo $1$ para indicar a presen√ßa de objeto, $4$ para indicar uma bounding box e $C$ para indicar a classe caso exista o objeto.\n",
    "\n",
    "Por exemplo, veja abaixo uma imagem e um tensor de sa√≠da de um modelo super simples de 1 camada convolucional (entenda o shape abaixo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d82d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.ones(3, 128, 128)\n",
    "modelo_simplorio = nn.Conv2d(in_channels=3, out_channels=1+4+10, kernel_size=16, stride=16)\n",
    "saida = modelo_simplorio(img)\n",
    "saida.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23151504",
   "metadata": {},
   "source": [
    "Vale lembrar que existem v√°rias formas poss√≠veis para essa realiza√ß√£o, neste lab iremos implementar a mais simples, que √© apenas uma bounding box por elemento do grid e o grid n√£o tem sobreposi√ß√£o. Em outras palavras, uma bounding box est√° associada apenas em um elemento do grid, aquele que contiver o seu centro, e cada grid cont√©m apenas uma bounding box.\n",
    "\n",
    "Nas arquiteturas estado-da-arte √© comum que um elemento do grid possa conter v√°rias bounding boxes (justamente para poder tratar o caso de. Na pr√≥pria YOLOv1 original um elemento do grid continha 2 BBs e em sua vers√£o posterior conteve 5 anchor boxes (que s√£o BBs de tamanhos j√° pr√©-definidos, *manjados*). √â claro que no caso de haverem v√°rias BBs voltamos no problema de fazer o match, s√≥ que agora √© muito mais controlado (quantidade bem pequena, 2-5 BBs) do que que se fiz√©ssemos na imagem inteira (dezenas, centenas de BBs).\n",
    "\n",
    "Nesse caso as v√°rias bounding boxes seriam mais dimens√µes sobre os canais de sa√≠da (entenda o shape abaixo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_simplorio_2bbs = nn.Conv2d(in_channels=3, out_channels=(1+4)*2+10, kernel_size=16, stride=16)\n",
    "saida2 = modelo_simplorio_2bbs(img)\n",
    "saida2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b8892",
   "metadata": {},
   "source": [
    "Al√©m disso, outra ideia interessante √© pemitir a sobreposi√ß√£o do grid ou ainda atribui√ß√£o de uma mesma BB a v√°rios elementos de grid pr√≥ximos. Porque isso, voc√™ deve estar se perguntando?\n",
    "\n",
    "Suponha, por exemplo, o caso em que o centro de uma BB caia exatamente (ou muito pr√≥ximo) da borda entre um grid e outro. Dependendo do que a rede atribuir e de como voc√™ construiu o tensor, a rede poder√° ser penalizada enormemente por um erro que deveria ser muito pequeno. Isso √© ruim e era exatamente um dos problemas que quer√≠amos evitar (s√≥ que ainda persiste em menor escala). Esse √© um caso extremo, mas d√° para intuir que seria interessante se os grids vizinhos pudessem compartilhar tamb√©m parte dessa informa√ß√£o.\n",
    "\n",
    "Para ajudar a rede a ser menos penalizada quando um objeto estiver bem na borda do grid, isto √©, pr√≥ximo de ser atribu√≠do a um grid vizinho e fazer a rede errar, podemos criar um overlapping entre os pr√≥prios grids.\n",
    "\n",
    "A forma exata desse overlapping depende da opera√ß√£o que foi empregada, sobretudo se houve ou n√£o *padding same*. Em geral as opera√ß√µes que reduzem as dimens√µes espaciais n√£o tem nenhum padding (*valid*) e usam stride igual ao tamanho do kernel, que em geral √© 2x2. Ent√£o se para a √∫ltima camada que reduz as dimens√µes espaciais ≈Ños coloc√°ssemos um stride 1 no lugar de 2 ter√≠amos grids que teriam overlapping de metade em cima do seus vizinho.\n",
    "\n",
    "Al√©m do overlapping podemos pensar da pr√≥pria atribui√ß√£o das BBs ao longo do grid, que em vez de atribuir apenas ao elemento do grid que cont√©m o centro da BB, atribuir tamb√©m aos vizinhos mais pr√≥ximos ou outros que estejam contidos na BB. (Essa √© uma ideia quase equivalente a anterior, mas s√≥ que agora em vez de atribuir a exatamente dois elementos do grid, atribuimos a mais)\n",
    "\n",
    "Enfim, s√£o outras poss√≠veis realiza√ß√µes do grid. Mas tamb√©m n√£o se esque√ßam que al√©m do grid (que √© o m√©todo de um √∫nico est√°gio), existem tamb√©m m√©todos de dois est√°gios (localizar, *recortar* e classificar), que √© ainda uma outra solu√ß√£o do problema original de detec√ß√£o.\n",
    "\n",
    "Essa √© uma outra ideia interessante para o exame, adaptar uma arquitetura de YOLO para ter overlapping de grids e/ou atribui√ß√µes m√∫ltiplas. Para quem quiser ser menos aventureiro, tamb√©m aplicar uma arquitetura estado-da-arte de detec√ß√£o de objetos no seu pr√≥prio dataset tamb√©m √© v√°lido! S√≥ tenha cuidado para n√£o fazer as duas coisas ao mesmo tempo: ou voc√™ cria uma arquitetura nova em um dataset conhecido ou voc√™ usa uma arquitetura conhecida em um dataset *novo*, justamente para poder realizar compara√ß√µes.\n",
    "\n",
    "Veja abaixo como as dimens√µes espaciais aumentaram quase dobraram (√© aquele $W_{final} = \\lfloor{\\frac{W_{img} - W_{kernel} + 1}{stride}}\\rfloor +1$ que o Gabriel pembou com o +1 na aula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_simplorio_overlapping = nn.Conv2d(in_channels=3, out_channels=(1+4)*2+10, kernel_size=16, stride=8)\n",
    "saida3 = modelo_simplorio_overlapping(img)\n",
    "saida3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180961c",
   "metadata": {},
   "source": [
    "**Enunciado da Quest√£o**\n",
    "\n",
    "Implemente a fun√ß√£o `monta_grid_detecta` abaixo, de acordo com a sua documenta√ß√£o. A ideia √© implementar o grid descrito acima da forma mais simples poss√≠vel: apenas uma BB por elemento do grid.\n",
    "\n",
    "No nosso caso simplificado, o grid n√£o tem overlapping, a bounding boxes deve ser\n",
    "associado por onde o seu centr√≥ide cair no grid. A posi√ß√£o dela deve ser RELATIVA a esse\n",
    "elemento do grid, sendo a origem no seu centro e sendo normalizado entre -1 e 1.\n",
    "As larguras e as alturas da bounding boxes devem ser normalizadas pela norms_bb, que\n",
    "representam a largura e altura m√©dia das BBs do conjunto de treino e com log.\n",
    "As classes devem ser codificadas como one-hot encodding (class_one_hot_encoding).\n",
    "Para um elemento do grid as classes devem ser ordenadas da seguinte forma:\n",
    "\n",
    "$[P_{obj}, Xc_{norm}, Yc_{norm}, W_{norm}, H_{norm}, class_{one hot encoding}]$\n",
    "\n",
    "$0 \\leq P_{obj} \\leq 1$ : probabilidade de haver objeto no grid\n",
    "\n",
    "$-1 \\leq X_{norm},Yc_{norm} < 1 $: posi√ß√£o do centroide da BB relativa ao centro do grid\n",
    "\n",
    "$W_{norm},H_{norm}$ : logaritmos da altura e largura da BB normalizadas\n",
    "\n",
    "Caso duas BBs caiam no mesmo grid, o comportamento esperado e que a √∫ltima (pela \n",
    "ordem da lista) sobreescreva as mais antigas.\n",
    "\n",
    "Os testes eles s√£o feitos passo-a-passo, ent√£o uma dica que eu deixo para voc√™ √© fazer tipo um TDD (Test-Driven Development) e ir implementando **CONSCIENTEMENTE** a fun√ß√£o passo-a-passo (baby-steps) e verificando se o seu pequeno passo est√° certo, por meio do teste (n√£o se esque√ßa de verificar se os testes antigos ainda funcionam)\n",
    "\n",
    "**N√ÉO** use LLMs (ChatGPT) para pegar a resposta pronta. **N√ÉO** pesquise a resposta pronta na internet.\n",
    "\n",
    "**Pode** olhar a documenta√ß√£o das bibliotecas (PyTorch, FastAI, mas todas as fun√ß√µes que voc√™ precisa est√° nas **dicas**) e **pode** (aconselhado) olhar o material de aula (slides e refer√™ncias).\n",
    "\n",
    "<details><summary><b>Dica para a resposta</b></summary>\n",
    "<p>\n",
    "    \n",
    "Precisa de um for-loop para percorrer a lista de bounding boxes e de classes juntas, em python d√° para voc√™ usar o operador `zip`, por exemplo: `for bbox, clas in zip(lista_bb, lista_classes):`\n",
    "\n",
    "Ent√£o para cada elemento modifique o valor j√° nas posi√ß√µes dimens√µes (canais) especificados e j√° normalizados.\n",
    "\n",
    "Fun√ß√µes da biblioteca pertinentes: `tensor`, `torch.zeros`, `torch.floor`, `torch.log`\n",
    "\n",
    "Use slices se quiser economizar linhas: `bbox[2:]` entre outros ... e d√° para fazer atribui√ß√£o de m√∫ltiplas vari√°veis com o valor de um array/lista: `idx, idy = [0, 0]`. A minha solu√ß√£o ficou com 8 linhas\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52b3e4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bc51bfd4f2f1810d73e331eb8ab953a",
     "grade": false,
     "grade_id": "questao_montar_tensor",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# questao_montar_tensor autograded_answer\n",
    "\n",
    "def monta_grid_detecta(lista_bb: Tensor, lista_classes: Tensor,\n",
    "                       C: int, W: int, H: int, S: int, norms_bb: Tensor) -> Tensor:\n",
    "    \"\"\" Cria o tesor da sa√≠da verdadeira definida pelas Bounding Boxes anotadas.\n",
    "    \n",
    "    Args:\n",
    "        lista_bb: Lista de bounding boxes definidas pelos v√©rtice x0, y0, wbb, hbb do\n",
    "            topo esquerdo e por sua largura e altura\n",
    "        lista_classes: Lista de classes associadas a cada bouding box respectivamente\n",
    "        C: n√∫mero de classes. O valores da lista_classes v√£o de 0 a C-1 inclusive.\n",
    "        W: largura da imagem em pixels (width)\n",
    "        H: altura da imagem em pixels (height)\n",
    "        S: tamanho em pixels de cada quadrado do grid de sa√≠da (size)\n",
    "        norms_bb: largura e altura m√©dias das BBs, isto √©, fatores de normaliza√ß√£o\n",
    "    \n",
    "    Returns:\n",
    "        Tensor de shape (1+4+C, H//S, W//S) que representa o grid de bounding boxes\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff72ec",
   "metadata": {},
   "source": [
    "Se voc√™ usou uma LLM, escreva a sua conversa com ela aqui nesta pr√≥pria c√©lula de texto (copie a conversa inteira) ou exporte o link da conversa:\n",
    "\n",
    "**Escreva aqui**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a2dec",
   "metadata": {},
   "source": [
    "Primeiro vamos verifica se com a entrada vazia n√≥s temos um tensor de tamanho correto e se as probabilidades de ter ou n√£o um objeto tamb√©m est√£o nulas (pois a lista de bounding boxes est√° vazia). Para isso voc√™ deve ter implementado a funcionalidade de inicializa√ß√£o do tensor de sa√≠da com os valores adequados (nulos para a probabilidade e qualquer valor para o resto).\n",
    "\n",
    "Entenda o que cada linha do teste faz, por exemplo, `torch.linalg.norm(saida - esperado) < ùúñ` calcula a norma euclidiana da diferen√ßa entre a sa√≠da e o valor esperado, e verifica se isso √© menor do que um n√∫mero muito pequeno $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b14d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78f66249e789632e88f8e33b60a2feb6",
     "grade": true,
     "grade_id": "testa_1_questao_montar_tensor",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1_questao_montar_tensor autograder_tests 0.2\n",
    "\n",
    "grid01 = monta_grid_detecta(lista_bb=tensor([]), lista_classes=tensor([]), C=8, \n",
    "                            W=100, H=100, S=10, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "assert grid01.shape == (13, 10, 10)\n",
    "assert grid01.dtype == torch.float32\n",
    "assert torch.linalg.norm(grid01[0] - torch.zeros(10, 10)) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0cb9b",
   "metadata": {},
   "source": [
    "E agora verificando se voc√™ n√£o inverteu largura por altura do grid (ainda para o caso da entrada vazia):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47434bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7853eff3ec5d219638f9f6fe196aacad",
     "grade": true,
     "grade_id": "testa_2_questao_montar_tensor",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_2_questao_montar_tensor autograder_tests 0.2\n",
    "\n",
    "grid02 = monta_grid_detecta(lista_bb=tensor([]), lista_classes=tensor([]), C=4, \n",
    "                            W=100, H=200, S=10, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "assert grid02.shape == (9, 20, 10)\n",
    "assert torch.linalg.norm(grid02[0] - torch.zeros(20, 10)) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946f004",
   "metadata": {},
   "source": [
    "Vamos verificar a probabilidade de haver um objeto. Fa√ßamos um grid 1x1 com uma bounding box centrada exatamente no meio, a probabilidade deve ser igual a 100%: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab38347",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "146de05ced0446353f2912e5471b1178",
     "grade": true,
     "grade_id": "testa_3_questao_montar_tensor",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_3_questao_montar_tensor autograder_tests 0.1\n",
    "\n",
    "grid03 = monta_grid_detecta(lista_bb=tensor([[0., 0, 77, 77]]), lista_classes=tensor([0]),\n",
    "                            C=5, W=77, H=77, S=77, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "assert grid03.shape == (10, 1, 1)\n",
    "assert grid03[0, 0, 0] == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb459f",
   "metadata": {},
   "source": [
    "Aumetemos o tamanho do grid e vejamos se ainda est√° funcionando a probabilidade de haver objeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c69d12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49dba98dbf35ffcd3824e26d523642d4",
     "grade": true,
     "grade_id": "testa_3b_questao_montar_tensor",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_3b_questao_montar_tensor autograder_tests 0.1\n",
    "\n",
    "grid03b = monta_grid_detecta(lista_bb=tensor([[20., 20, 20, 20]]), lista_classes=tensor([3]),\n",
    "                             C=4, W=100, H=100, S=20, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "probs = tensor([[0., 0., 0., 0., 0.],\n",
    "                [0., 1., 0., 0., 0.],\n",
    "                [0., 0., 0., 0., 0.],\n",
    "                [0., 0., 0., 0., 0.],\n",
    "                [0., 0., 0., 0., 0.]])\n",
    "\n",
    "assert grid03b.shape == (9, 5, 5)\n",
    "assert torch.linalg.norm(grid03b[0] - probs) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c8a43",
   "metadata": {},
   "source": [
    "Voltando para o caso 1x1. Vamos verificar se a classe est√° correta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d75c93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a85ab66f06fdfa7b9ee8d44dd860197",
     "grade": true,
     "grade_id": "testa_4_questao_montar_tensor",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_4_questao_montar_tensor autograder_tests 0.2\n",
    "\n",
    "grid04 = monta_grid_detecta(lista_bb=tensor([[0., 0, 8, 8]]), lista_classes=tensor([0]),\n",
    "                            C=5, W=8, H=8, S=8, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "classe_one_hot = tensor([1, 0, 0, 0, 0])\n",
    "\n",
    "assert grid04.shape == (10, 1, 1)\n",
    "assert torch.linalg.norm(grid04[5:, 0, 0] - classe_one_hot) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8cd47",
   "metadata": {},
   "source": [
    "Vamos verificar o centro dessa BB, perceba que eu coloquei ela exatamente no quadrante do fundo direito do grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a831712",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f283d31d2cf40c6c9f583ac2cc26f002",
     "grade": true,
     "grade_id": "testa_5_questao_montar_tensor",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_5_questao_montar_tensor autograder_tests 0.2\n",
    "\n",
    "grid05 = monta_grid_detecta(lista_bb=tensor([[40., 40, 40, 40]]), lista_classes=tensor([0]),\n",
    "                            C=5, W=80, H=80, S=80, norms_bb=tensor([1., 1.]))\n",
    "\n",
    "centro = tensor([0.5, 0.5])\n",
    "\n",
    "assert grid05.shape == (10, 1, 1)\n",
    "assert torch.linalg.norm(grid05[1:3, 0, 0] - centro) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37705d33",
   "metadata": {},
   "source": [
    "E ver se voc√™ est√° fazendo as normaliza√ß√µes da bounding boxes corretamente, temos uma bounding box com 60 pixels de largura e 50 pixels de altura mas o tamanho m√©dio das BBs do treino s√£o de 30 pixels de largura e 20 pixels de altura. Portanto em termos relativos (multiplicativos) a nossa largura e altura normalizadas devem ser de 2 e de 2.5 respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35515a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82eafbbe25952c3d0c3c79180e95b0ac",
     "grade": true,
     "grade_id": "testa_6_questao_montar_tensor",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_6_questao_montar_tensor autograder_tests 0.2\n",
    "\n",
    "grid06 = monta_grid_detecta(lista_bb=tensor([[0, 0, 60, 50]]), lista_classes=tensor([0]), C=5, \n",
    "                            W=80, H=80, S=80, norms_bb=tensor([30., 20.]))\n",
    "\n",
    "largura_altura = torch.log(tensor([2, 2.5]))\n",
    "\n",
    "assert grid06.shape == (10, 1, 1)\n",
    "assert torch.linalg.norm(grid06[3:5, 0, 0] - largura_altura) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c314d3e",
   "metadata": {},
   "source": [
    "E finalmente realizamos o teste com dados reais. Voc√™ consegue olhar para as matrizes abaixo e enxergar os valores n√£o nulos e entender porque deles serem assim? Olha na imagem abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385187d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "689d09a1e75544f62b2a5089380da1ad",
     "grade": true,
     "grade_id": "testa_7_questao_montar_tensor",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_7_questao_montar_tensor autograder_tests 1\n",
    "\n",
    "bbs_testa = tensor([\n",
    "    [22.0, 0.0, 98.0, 88.0],\n",
    "    [19.0, 0.0, 396.0, 415.0],\n",
    "    [0.0, 166.0, 131.0, 249.0]])\n",
    "categorias_testa = tensor([3, 2, 2])\n",
    "\n",
    "probs = tensor(\n",
    "    [[0., 1., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 1., 0., 0., 0.],\n",
    "     [0., 1., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.]])\n",
    "x_norms = tensor(\n",
    "    [[ 0.0000, -0.7812,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000,  0.0000,  0.0000, -0.2188,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000, -0.9531,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "     [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
    "h_norms = tensor(\n",
    "    [[0.0000, 0.0394, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 1.5903, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 1.0795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "     [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "class_terror = tensor(\n",
    "    [[0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 1., 0., 0., 0.],\n",
    "     [0., 1., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.],\n",
    "     [0., 0., 0., 0., 0., 0., 0.]])\n",
    "\n",
    "grid07 = monta_grid_detecta(\n",
    "    lista_bb=bbs_testa, lista_classes=categorias_testa,\n",
    "    C=4, W=448, H=448, S=64, norms_bb=tensor([55.5, 84.6]))\n",
    "\n",
    "assert grid07.shape == (9, 7, 7)\n",
    "assert torch.linalg.norm(grid07[0] - probs) < 1e-3\n",
    "assert torch.linalg.norm(grid07[1] - x_norms) < 1e-3\n",
    "assert torch.linalg.norm(grid07[4] - h_norms) < 1e-3\n",
    "assert torch.linalg.norm(grid07[7] - class_terror) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfdf42",
   "metadata": {},
   "source": [
    "Tem outras dimens√µes y e w que n√£o coloquei os tensores, mas d√™ uma olhada na imagem e veja se faz sentido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a044c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dado_testa = cs_dataset['train'][1063]\n",
    "if RETRAIN:\n",
    "    plot_dado(dado_testa, grid=64, desenha_centros=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb8ab2",
   "metadata": {},
   "source": [
    "## Definindo a Arquitetura (2 pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52f7ab",
   "metadata": {},
   "source": [
    "**Explica√ß√£o sobre o assunto**\n",
    "\n",
    "No lab passado n√≥s vimos uma arquitetura de rede neural para classifica√ß√£o de imagens e tamb√©m como realizar um transfer learning. Se voc√™ tiver realmente entendido o lab passado, voc√™ j√° deve conseguir enxergar uma pequena modifica√ß√£o no final daquela arquitetura que faz com que o tensor de sa√≠da dela seja um *grid*. Mesmo que n√£o tenha percebido isso no lab passado, n√£o tem problema, pois tamb√©m explicaremos novamente neste lab.\n",
    "\n",
    "O ponto fundamental para essa compreens√£o √© entender a opera√ß√£o de convolu√ß√£o e observar que a rede neural que contru√≠mos √© composta puramente de opera√ß√µes convolucionais (e seus equivalentes matem√°ticos que operam elemento-a-elemento, ativa√ß√µes, normaliza√ß√µes). Dessa forma, a cada camada n√≥s temos uma entrada que √© uma *imagem* (ou batch de imagens) da forma $(\\ldots, C_{in}, H_{in}, W_{in})$, que tem $C_{in}$ canais (n√£o necessariamente de cores, mas de ativa√ß√µes que n√£o sabemos exatamente o que significam), e dimens√µes espaciais de altura $H_{in}$ e de largura $W_{in}$. A nossa opera√ß√£o de convolu√ß√£o vai agir de forma local sobre as dimens√µes espaciais e de forma *global* sobre os canais (a priori todos os canais de entrada est√£o conectados com os de sa√≠da).\n",
    "\n",
    "Dessa forma, ap√≥s uma convolu√ß√£o ou uma sequ√™ncia de convolu√ß√µes, ainda continuamos com um tensor da forma $(\\ldots, C_{out}, H_{out}, W_{out})$, com dimens√µes de canais de dimens√µes espaciais.\n",
    "\n",
    "Tamb√©m √© importante que voc√™ entenda a forma como a informa√ß√£o se propaga pelas dimens√µes espaciais e como as larguras e as alturas mudam (se permanecem iguais gra√ßas a um *padding same*, ou se diminuem nas bordas, ou ainda por um fator inteiro gra√ßas ao *stride*).\n",
    "\n",
    "Em especial, como as dimens√µes espacial s√£o reduzidas, se h√° overlapping ou se h√° *distor√ß√µes* nas bordas. Por exemplo, a quest√£o anterior do grid precisa de convolu√ß√µes com *padding same* (que n√£o mude os tamanhos espaciais) justamente para poder fazer uma proje√ß√£o direta (usar a regra de 3, s√≥ dividir pelo S) do grid sobre a imagem de entrada. E ainda para n√£o ter overlapping, √© necess√°rio que as opera√ß√µes que reduzam a dimens√£o tenham stride igual ao tamanho do kernel, em geral 2x2 com stride 2 que reduz exatamente pela metade, e sem nenhum padding (apenas *valid*).  \n",
    "\n",
    "O c√≥digo abaixo ([Github](https://github.com/facebookresearch/ConvNeXt)) √© do [Meta AI Research](https://ai.meta.com/research/), do modelo ConvNext, que √© um tipo de ResNet mais moderna, com normaliza√ß√£o por camadas (*LayerNorm*), convolu√ß√µes puramente espaciais (com tantos grupos quanto canais, *depthwise*) e dropout nas pr√≥prias conex√µes residuais (*DropPath*).\n",
    "\n",
    "Aten√ß√£o, a `ConvNeXt` abaixo √© apenas para classifica√ß√£o (sa√≠da logits da softmax), o trabalho de voc√™s vai ser mudar as √∫ltimas camadas para permitir a detec√ß√£o (sa√≠da grid).\n",
    "\n",
    "S√≥ para aquecer vamos come√ßar pelo o `LayerNorm` abaixo. Eles fizeram duas implementa√ß√µes diferentes na mesma classe, uma para o caso unidimensional, que s√£o os `channels_last` e outra para o caso 2d que trabalhamos no PyTorch, com os `channels_first`. Ambos s√£o uma normaliza√ß√£o subtrai a m√©dia e divide pelo desvio padr√£o, e que tem par√¢metros de escala (`weight` e `bias`) a serem treinados. A √∫nica diferen√ßa est√° nas dimens√µes em que as opera√ß√µes s√£o realizadas. No caso 2d (`channels_first`), ele reduz a dimens√£o 1 que s√£o os canais, o `C` do (B,C,H,W) para calcular a m√©dia e o desvio padr√£o, assim n√£o h√° influ√™ncia espacial nessa normaliza√ß√£o (cada pixel √© separado e depende apenas dos seus canais).\n",
    "\n",
    "*(n√£o precisa entender o c√≥digo abaixo (que os pesquisadores implementaram), mas √© importante que voc√™ entenda a explica√ß√£o acima*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7de3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0262dc",
   "metadata": {},
   "source": [
    "Em seguida temos o bloco da rede convolucional do MetaAI, que √© bem semelhante ao que voc√™s implementaram no lab passado. A principal diferen√ßa est√° em uma regulariza√ß√£o da conex√£o residual, por meio do `DropPath`, que tal qual o *DropOut*, tem uma probabilidade de zerar completamente os valores, s√≥ que agora n√£o das ativa√ß√µes dos neur√¥nios, mas da pr√≥pria conex√£o residual.\n",
    "\n",
    "Perceba que as dimens√µes de entrada s√£o exatamente as mesmas de sa√≠da, ele n√£o altera nem a quantidade de canais (apesar de que internamente ele aumenta 4 vezes e depois diminui os canais para ficar igual da entrada), nem as dimens√µes espaciais (pois usa padding).\n",
    "\n",
    "Algo que eu achei bem interessante foi o fato deles usarem uma camada densa no lugar de uma conv1x1. √â matematicamente equivalente, s√≥ que eles tiveram mais trabalho para fazer reshape antes e reshape depois. Talvez eles tenham feito isso por performance (por que se eles tivessem deixado a conv1x1 nem precisariam ter implementado a LayerNorm com channels_last). Algo muito ruim (do ponto de vista de engenharia) que eles fizeram foi nomear uma vari√°vel `input`, pois √© uma palavra reservada do Python.\n",
    "\n",
    "*(n√£o precisa entender o c√≥digo abaixo (que os pesquisadores implementaram), mas √© importante que voc√™ entenda a explica√ß√£o acima*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b7836",
   "metadata": {},
   "source": [
    "Finalmente temos a defini√ß√£o final da ConvNeXt. O c√≥digo est√° exatamente como reportado pelos pesquisadores, eu n√£o alterei nada (√© para voc√™s verem como os pesquisadores de IA escrevem c√≥digo para divulga√ß√£o, que em geral leva mais trabalho para entender).\n",
    "\n",
    "Em termos simplificado ele inst√¢ncia 4 camadas de *downsampling* e 4 conjunto de camadas de blocos (cada conjunto tem m√∫ltiplos blocos), e por √∫ltimo tem o `self.head` e o `self.norm` que n√≥s iremos alterar.\n",
    "\n",
    "√â importante que voc√™ conhe√ßa que o *downsamplings* diminuem as dimens√µes espaciais, respectivamente por 4, por 2, por 2 e por 2. Assim, a redu√ß√£o total √© de 32 vezes, que gera o nosso grid (o tamanho dele). Entendeu o porqu√™ do tamanho do grid?\n",
    "\n",
    "*(n√£o precisa entender o c√≥digo abaixo [(que os pesquisadores implementaram)](https://github.com/facebookresearch/ConvNeXt/blob/main/models/convnext.py), mas √© importante que voc√™ entenda a explica√ß√£o acima*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ae4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    r\"\"\" ConvNeXt\n",
    "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "\n",
    "    Args:\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_chans=3, num_classes=21841, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.head = nn.Linear(dims[-1], num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b24c3",
   "metadata": {},
   "source": [
    "Agora esse m√©todo √© importante (o nome dele √© arbitr√°rio), mas prestem aten√ß√£o pois voc√™s devem cham√°-lo para facilitar a sua vida. Entenda o c√≥digo abaixo.\n",
    "\n",
    "Esse m√©todo realiza a propaga√ß√£o direta at√© o ponto em que o tensor `x` ainda mant√©m as suas dimens√µes espaciais. Ou seja, ele passa por todas as camadas anteriores, que reduz por um fator de 32 as dimens√µes espaciais e aumenta os canais para 768 (no modelo *tiny*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e30d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(ConvNeXt)\n",
    "def forward_features(self: ConvNeXt, x: Tensor) -> Tensor:\n",
    "    for i in range(4):\n",
    "        x = self.downsample_layers[i](x)\n",
    "        x = self.stages[i](x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81876aa",
   "metadata": {},
   "source": [
    "Esse m√©todo √© o `forward` que voc√™s j√° devem estar habituados (o nome dele √© importante para o PyTorch poder cham√°-lo no __call__ do objeto).\n",
    "\n",
    "Observe que a entrada √© uma imagem, um tensor de shape $(B, 3, H, W)$. Em seguida ele chama o m√©todo da c√©lula acima para obter um tensor de de shape $(B, 768, H//32, W//32)$ que foi o resultado de muitas convolu√ß√µes.\n",
    "\n",
    "Depois ele realiza uma redu√ß√£o das dimens√µes espaciais, fazendo uma m√©dia desses valores. E por fim utiliza uma camada densa (completamente conectada, a `head`) para calcular os *logits* de sa√≠da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(ConvNeXt)\n",
    "def forward(self: ConvNeXt, x: Tensor) -> Tensor:\n",
    "    x = self.forward_features(x)\n",
    "    x = self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "    x = self.head(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbadcc8",
   "metadata": {},
   "source": [
    "Assim, temos a ConvNeXt completamente definida (todos as suas camadas, blocos e opera√ß√µes).\n",
    "\n",
    "Vamos baixar os par√¢metros j√° treinados no ImageNet mais recente de 22 mil imagens (22k no lugar do 1k). √â do reposit√≥rio do Facebook (Meta AI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\"\n",
    "classification_weights = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf5970c",
   "metadata": {},
   "source": [
    "Vamos instanciar a rede deles e carregar os seus pesos j√° treinados para classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19507a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeXt()\n",
    "model.load_state_dict(classification_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85503f4b",
   "metadata": {},
   "source": [
    "Perceba como √© a sa√≠da antes de passar pelas √∫ltimas camadas `head`, para uma imagem de shape `(1, 3, 416, 416)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rand = torch.rand((1, 3, 416, 416))\n",
    "features = model.forward_features(img_rand)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45111077",
   "metadata": {},
   "source": [
    "E como ela fica no final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_final_classificacao = model(img_rand)\n",
    "output_final_classificacao.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a88cf",
   "metadata": {},
   "source": [
    "Enfim, vamos definir a nossa pr√≥pria rede convolucional de detec√ß√£o, a `ConvDect`! Baseada na estrutura da `ConvNeXt`\n",
    "\n",
    "Perceba que eu deletei as camadas `head` e `norm` da rede de classifica√ß√£o. Criei um `bloco_final1` que n√£o altera o shape do tensor de entrada, mas que √© apenas a aplica√ß√£o de uma conv3x3 com padding same que age independemente para cada canal, isto √©, puramente espacial (pois `groups==channels`) seguida de uma conv1x1 que age apenas nos canais (768). Todas essas convolu√ß√µes tem fun√ß√£o de ativa√ß√£o GELU ap√≥s as ativa√ß√µes. Essa sequ√™ncia de convolu√ß√µes √© repetiva por 4 vezes.\n",
    "\n",
    "Deve haver uma conex√£o residual ap√≥s o `bloco_final1`, o que √© simples uma vez que o shape n√£o mudou. Em seguida aplica-se a camada `apos_res` ap√≥s a conex√£o residual para poder reduzir a quantidade de canais (reduz de 768 para 192). Essa camada tamb√©m deve ter fun√ß√£o de ativa√ß√£o GELU.\n",
    "\n",
    "Novamente h√° o `bloco_final2` que √© an√°logo ao 1, s√≥ que agora s√£o menos canais (192). H√° tamb√©m a √∫ltima convolu√ß√£o que altera de a quantidade de canais para a sa√≠da esperada: 1 probabilidade, 2 posi√ß√µes x/y normalizados, 2 larguras/alturas normalizadas e `num_classes` logits das probabilidades de pertencer √† classe. A probabilidade deve ter fun√ß√£o de ativa√ß√£o softmax e os x/y normalizados devem ter fun√ß√£o de ativa√ß√£o tangente hiperb√≥lica.\n",
    "\n",
    "DISCLAIMER: Essas camadas que eu criei s√£o arbitr√°rias mas motivadas na arquitetura da ConvNeXt (poderia ser diferente sem problemas), mas voc√™ deve implement√°-las exatamente como na descri√ß√£o para passar nos testes. Por exemplo, usar uma conv3x3 puramente espacial e depois uma conv1x1 tem menos par√¢metros e computa√ß√£o do que usar uma conv3x3 normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDect(ConvNeXt):\n",
    "    \"\"\" Rede Convolucional para Detec√ß√£o de Objetos, baseada na ConvNext que\n",
    "    era uma rede apenas de classifica√ß√£o.\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of classes for classification head.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__(num_classes=num_classes)\n",
    "        del self.norm\n",
    "        del self.head\n",
    "        self.bloco_final1 = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.Conv2d(768, 768, 3, padding='same', groups=768),\n",
    "                nn.GELU(),\n",
    "                nn.Conv2d(768, 768, 1),\n",
    "                nn.GELU())\n",
    "            for i in range (4)]\n",
    "        )\n",
    "        self.apos_res = nn.Conv2d(768, 192, 1)\n",
    "        self.bloco_final2 = nn.Sequential(\n",
    "            *([nn.Sequential(\n",
    "                nn.Conv2d(192, 192, 3, padding='same', groups=192),\n",
    "                nn.GELU(),\n",
    "                nn.Conv2d(192, 192, 1),\n",
    "                nn.GELU())\n",
    "            for i in range (4)] +\n",
    "           [nn.Conv2d(192, 1 + 4 + num_classes, 1)])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbeb922",
   "metadata": {},
   "source": [
    "**Enunciado da Quest√£o**\n",
    "\n",
    "Implemente a fun√ß√£o `forward` abaixo na classe `ConvDect` que √© a nossa pr√≥pria rede de detec√ß√£o baseada na do MetaAI.\n",
    "\n",
    "H√° uma conex√£o residual depois do `bloco_final1` e antes do `apos_res`\n",
    "A sa√≠da do apos_res deve passa por uma fun√ß√£o de ativa√ß√£o GELU\n",
    "A sa√≠da final deve ter fun√ß√£o de ativa√ß√£o Sigm√≥ide para o canal 0 ($P_{obj}$)\n",
    "e ativa√ß√£o Tangente Hiperb√≥lica para os canais 1 e 2 ($Xc_{norm}, Yc_{norm}$).\n",
    "\n",
    "**N√ÉO** use LLMs (ChatGPT) para pegar a resposta pronta.\n",
    "\n",
    "**Pode** olhar a documenta√ß√£o das bibliotecas (PyTorch, FastAI, mas todas as fun√ß√µes que voc√™ precisa est√° nas **dicas**) e **pode** (aconselhado) olhar o material de aula (slides e refer√™ncias).\n",
    "\n",
    "<details><summary><b>Dica para a resposta</b></summary>\n",
    "<p>\n",
    "Basta voc√™ chamar os blocos e a camada que eu declarei. N√£o se esque√ßa da conex√£o residual nem das fun√ß√µes de ativa√ß√£o `F.gelu`, `F.sigmoid`, `F.tanh`.\n",
    "A minha solu√ß√£o ficou com 5 linhas.\n",
    "\n",
    "Outras fun√ß√µes da biblioteca interessantes: `torch.cat`\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a245ae5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0f877b93fb0c4d08874828639097211",
     "grade": false,
     "grade_id": "questao_arquitetura",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# questao_arquitetura autograded_answer\n",
    "\n",
    "@patch_to(ConvDect)\n",
    "def forward(self: ConvDect, x: Tensor) -> Tensor:\n",
    "    \"\"\" Realiza a propaga√ß√£o direta da rede, utiliza todas as camadas da\n",
    "    rede antiga (at√© a parte com dimens√µes espaciais) e tamb√©m todas as\n",
    "    camadas definidas posteriores no m√©todo init.\n",
    "\n",
    "    Args:\n",
    "        x: tensor de entrada (imagem de entrada) de shape (B, 3, H, W)\n",
    "\n",
    "    Returns:\n",
    "        tensor de grid com shape (B, 5+num_classes, H//32, W//32)\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7e773",
   "metadata": {},
   "source": [
    "Se voc√™ usou uma LLM, escreva a sua conversa com ela aqui nesta pr√≥pria c√©lula de texto (copie a conversa inteira) ou exporte o link da conversa:\n",
    "\n",
    "**Escreva aqui**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b94db",
   "metadata": {},
   "source": [
    "Verifica se o shape de sa√≠da est√° correto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f2d50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f49706640d8390fec4abab41d0d86622",
     "grade": true,
     "grade_id": "testa_1_questao_arquitetura",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1_questao_arquitetura autograder_tests 0.2\n",
    "\n",
    "img_test0 = torch.rand(1, 3, 416, 448)\n",
    "model = ConvDect(40)\n",
    "\n",
    "saida0 = model(img_test0)\n",
    "\n",
    "assert saida0.shape == (1, 45, 13, 14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406bba77",
   "metadata": {},
   "source": [
    "Verifica se as fun√ß√µes de ativa√ß√£o realmente est√£o limitando as sa√≠das conforme o esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b4655",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc2089fb3039aa47f4a053451a05e3ed",
     "grade": true,
     "grade_id": "testa_1b_questao_arquitetura",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1b_questao_arquitetura autograder_tests 0.3\n",
    "\n",
    "img_test0b = torch.rand(4, 3, 448, 448) * 4 - 2\n",
    "model = ConvDect(4)\n",
    "\n",
    "saida0b = model(img_test0)\n",
    "\n",
    "assert torch.all(saida0b[:, 0] <= 1)\n",
    "assert torch.all(saida0b[:, 0] >= 0)\n",
    "\n",
    "assert torch.all(saida0b[:, 1:3] <= 1)\n",
    "assert torch.all(saida0b[:, 1:3] >= -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea26fb8",
   "metadata": {},
   "source": [
    "Verifica se todos os sub-m√≥dulos pertinentes foram chamados, isto √©, se os gradientes n√£o est√£o nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc665c90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9b19f25852cca88d05f526aec42574",
     "grade": true,
     "grade_id": "testa_2_questao_arquitetura",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_2_questao_arquitetura autograder_tests 0.5\n",
    "\n",
    "img_test2 = torch.rand(1, 3, 448, 448) * 4 - 2\n",
    "model = ConvDect(4)\n",
    "\n",
    "saida2 = model(img_test2)\n",
    "saida2.sum().backward()\n",
    "\n",
    "for param in model.parameters():\n",
    "    assert torch.linalg.norm(param.grad) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147bac87",
   "metadata": {},
   "source": [
    "Testa na rede final j√° treinada em um dado do nosso dataset (aten√ß√£o para a conex√£o residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54490695",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e26614cb8c0181c91b714ad41b176f5",
     "grade": true,
     "grade_id": "testa_3_questao_arquitetura",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_3_questao_arquitetura autograder_tests 1\n",
    "\n",
    "img_test3 = IntToFloatTensor()(ToTensor()(\n",
    "    PILImage(cs_dataset['train'][1063]['image'])))[None]\n",
    "model = ConvDect(4)\n",
    "model.load_state_dict(torch.load(base_path/'treinado.pth', map_location=\"cpu\"))\n",
    "\n",
    "saida3 = model(img_test3)\n",
    "\n",
    "assert saida3.shape == (1, 9, 13, 13)\n",
    "assert torch.linalg.norm(saida3[0, 0] - tensor(\n",
    "   [[0.  , 0.  , 0.1 , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.02, 0.95, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.01, 0.01, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.1 , 0.01, 0.16, 0.09, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
    "    [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])).item() < 0.02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5eb55",
   "metadata": {},
   "source": [
    "Para o nosso treinamento iremos fazer um transfer learning a partir da rede de classifica√ß√£o j√° treinada congelar todos os outros par√¢metros a menos dos nossos que fizemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c87715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_learning(rede: ConvDect, pesos: dict[str, Tensor]):\n",
    "    rede.load_state_dict(pesos, strict=False)\n",
    "    for module in rede.modules():\n",
    "        module.eval()\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n",
    "    for module in [rede.bloco_final1, rede.apos_res, rede.bloco_final2]:\n",
    "        module.train()\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398e430",
   "metadata": {},
   "source": [
    "No mundo real √© melhor que voc√™ fa√ßa o transfer learning de uma rede treinada j√° em detec√ß√£o, e n√£o em classifica√ß√£o como estamos fazendo aqui. O intuito desse lab √© mostrar para voc√™s justamente como funciona uma rede de detec√ß√£o single-stage (tipo YOLO) e a forma mais f√°cil √© partir justamente de uma rede que j√° faz classifica√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1dc1e2",
   "metadata": {},
   "source": [
    "## Definindo a Fun√ß√£o Custo (2 pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8efa9",
   "metadata": {},
   "source": [
    "**Explica√ß√£o sobre o assunto**\n",
    "\n",
    "Agora que j√° temos a nossa sa√≠da esperada e a nossa rede que calcula a sa√≠da estimada, precisamos de uma fun√ß√£o custo para poder compar√°-las e obter um valor √öNICO para poder fazer a retropropaga√ß√£o!\n",
    "\n",
    "Pelo fato de termos apenas uma BB por elemento do grid, fica bem mais f√°cil, n√£o precisamos ficar nos preocupando em dar match de BB. Lembrando que no match n√≥s alteramos o valor da sa√≠da esperada de forma a penalizar menos a rede, assim o processo do match em si n√£o precisa ser retropropagado (alteramos apenas um tensor que n√£o requer gradiente). √â como se o *professor* fosse mais compreensivo com o aluno durante a corre√ß√£o, isto √©, o aluno deu uma resposta que n√£o √© exatamente igual ao que o professor esperava mas que n√£o est√° essencialmente errada, s√≥ precisa de um outro *ponto de vista*.\n",
    "\n",
    "Mas no nosso caso que temos apenas uma BB fica mais simples, basta comparar os valores diretamente. Mas √© importante entender que cada valor (probabilidade, posi√ß√£o, largura, probabilidade de classes) s√£o comparados de uma forma diferente e com pesos (weights) diferentes, caso queiramos que a rede seja mais sens√≠vel para localiza√ß√£o ou para a classifica√ß√£o.\n",
    "\n",
    "Por exemplo as posi√ß√µes X, Y, podemos simplesmente aplicas uma MSE, que √© simplesmente subtrair o valor verdadeiro y do valor estimado ≈∑ e elevar ao quadrado. Uma coisa interessante a se notar √© a forma de combinar esses custos ao longo das dimens√µes (sobretudo dos batches), que pode ser um somat√≥rio ou uma m√©dia. Al√©m disso, para as fun√ß√µes custo do PyTorch d√° para passar `reduction='none'` que n√£o faz a redu√ß√£o das dimens√µes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c51c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, ≈∑ = torch.rand(3, 3), torch.rand(3, 3)\n",
    "F.mse_loss(≈∑, y, reduction='none'), (≈∑ - y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef13807",
   "metadata": {},
   "source": [
    "Por *default* a redu√ß√£o √© a m√©dia `reduction='mean'` e significa a aplica√ß√£o de um `torch.mean` sobre o resultado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.binary_cross_entropy(torch.rand(3, 4), torch.rand(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23811d9",
   "metadata": {},
   "source": [
    "A `F.cross_entropy` calcula a entropia cruzada sobre os *logits*, como vimos no lab passado (cuidado com a ordem de ≈∑, e y que importa, pois √© probabilidade vezes o log). Agora tamb√©m vamos aplicar a\n",
    "\n",
    "Veja como a segunda dimens√£o (dim=1) √© reduzida, no exemplo abaixo era $(3, 4, 6, 8)$ que virou $(3, 6, 8)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(torch.rand(3, 4, 6, 8), torch.rand(3, 4, 6, 8), reduction='none').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928256e",
   "metadata": {},
   "source": [
    "A nossa loss completa √© uma fun√ß√£o perda multi-tarefa (*multi-task*) que utiliza entropia bin√°ria (BCE - *binary cross entropy*) para o problema da classifica√ß√£o bin√°ria sobre as probabilidades de haver objeto ou n√£o $p_{obj}$; erro quadr√°tico m√©dio (*MSE*) para os problemas de localiza√ß√£o e de estimativa do tamanho da BB; e entropia cruzada (*CE - cross entropy*) para o problema de classifica√ß√£o entre as classes. Cada problema √© ponderado por um fator $\\lambda$ que indica a import√¢ncia relativa dele. Al√©m disso, as outras losses s√≥ fazem sentido se realmente houver algo no grid (s√£o condicionados ao valor de $p_{obj}$ verdadeiro). Isto √©, os outros valores (posi√ß√£o, tamanho, classe) n√£o importam se n√£o houver nada no grid de verdade (imagem fazia, por exemplo).\n",
    "\n",
    "A formula√ß√£o matem√°tica da loss total est√° abaixo, mas n√£o recomendo que voc√™ implemente conforme essa f√≥rmula, mas que use j√° cada loss pronta do PyTorch `F.`\n",
    "\n",
    "$L = \\frac{1}{B H W} \\sum_B \\sum_H \\sum_W \\left ( \\\\\n",
    "-\\lambda_{BCE} p_{obj} \\log{\\hat{p}_{obj}} - \\lambda_{BCE} (1-p_{obj}) \\log(1-\\hat{p}_{obj}) \\\\\n",
    "+p_{obj}\\frac{\\lambda_{pos}}{2} (\\hat{x}-x)^2 + p_{obj}\\frac{\\lambda_{pos}}{2} (\\hat{y}-y)^2 \\\\\n",
    "+p_{obj}\\frac{\\lambda_{size}}{2} (\\hat{w}-w)^2 + p_{obj}\\frac{\\lambda_{size}}{2} (\\hat{h}-h)^2 \\\\\n",
    "-p_{obj}\\frac{\\lambda_{class}}{C} \\sum_C p_{c} \\log{\\hat{p}_{c}} \\\\\n",
    "\\right )$\n",
    "\n",
    "Por exemplo: (na sua implementa√ß√£o voc√™ tem que ser mais esperto do que esse exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * F.mse_loss(≈∑, y) + 4 * F.cross_entropy(≈∑, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666152d5",
   "metadata": {},
   "source": [
    "**Enunciado da Quest√£o**\n",
    "\n",
    "Implemente a fun√ß√£o `loss_func` abaixo, que √© interna √† `nanoyolo_loss`, que calcula a *dist√¢ncia* entre o grid verdadeiro e o grid esperado.\n",
    "\n",
    "**FA√áA VETORIZADO**\n",
    "\n",
    "Essa quest√£o com os testes tamb√©m ficou boa para fazer com TDD (*Test-Driven Development*).\n",
    "\n",
    "**N√ÉO** use LLMs (ChatGPT) para pegar a resposta pronta. **N√ÉO** pesquise a resposta pronta na internet.\n",
    "\n",
    "**Pode** olhar a documenta√ß√£o das bibliotecas (PyTorch, FastAI, mas todas as fun√ß√µes que voc√™ precisa est√° nas **dicas**) e **pode** (aconselhado) olhar o material de aula (slides e refer√™ncias).\n",
    "\n",
    "<details><summary><b>Dica para a resposta</b></summary>\n",
    "<p>\n",
    "\n",
    "Use os bizus das explica√ß√µes acima, voc√™ pode implementar a sua pr√≥pria loss, mas recomendo usar o `F.binary_cross_entropy`, o `F.mse_loss` e o `F.cross_entropy`, `torch.mean`. Seja esperto no broadcasting e nos slices.\n",
    "\n",
    "A minha implementa√ß√£o vetorizada ficou com 4 linhas, uma para cada tipo de loss, √© apenas um return. Seja esperto no broadcasting e nos slices.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1dbb0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b3b62640c6ad48422724a860f334936",
     "grade": false,
     "grade_id": "questao_loss_func",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# questao_loss_func autograded_answer\n",
    "\n",
    "\n",
    "def nanoyolo_loss(bce_w=1., pos_w=1., size_w=1., class_w=1.):\n",
    "    \"\"\"Retorna a loss function combinada para a classifica√ß√£o bin√°ria (BCE)\n",
    "    na probabilidade de haver objeto p_obj, para a localiza√ß√£o e tamanho (MSE),\n",
    "    e para a classifica√ß√£o (CE), ponderados pelos seus respectivos pesos. As\n",
    "    de MSE e CE s√£o ponderadas pelo p_obj verdadeiro. A redu√ß√£o √© a m√©dia das\n",
    "    dimens√µes.\n",
    "    \n",
    "    Args:\n",
    "        bce_w: Fator de peso sobre a entropia bin√°ria (de probabilidade)\n",
    "        pos_w: Fator de peso sobre o MSE da posi√ß√£o\n",
    "        size_w: Fator de peso sobre o MSE da largura/altura da BB\n",
    "        class_w: Fator de peso para a entropia cruzada de classifica√ß√£o\n",
    "    \n",
    "    Returns:\n",
    "        Tensor de rank 0 que √© loss total\n",
    "    \"\"\"\n",
    "    def loss_func(≈∑: Tensor, y: Tensor) -> Tensor:\n",
    "        # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "        raise NotImplementedError()\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0fe73",
   "metadata": {},
   "source": [
    "Se voc√™ usou uma LLM, escreva a sua conversa com ela aqui nesta pr√≥pria c√©lula de texto (copie a conversa inteira) ou exporte o link da conversa:\n",
    "\n",
    "**Escreva aqui**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475dcf61",
   "metadata": {},
   "source": [
    "Para uma sa√≠da estimada $\\hat{y}$ que √© exatamente igual √† sa√≠da verdadeira o resultado dessa fun√ß√£o deve ser zero. Al√©m disso, deve ser um tensor de rank 0 (escalar do PyTorch).\n",
    "\n",
    "No caso abaixo testamos com tudo zerado, pois as probabilidades, al√©m de serem iguais, devem ter valor 0 ou 1 para que as entropias sejam nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49525e5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c277bf4f76d8733f68bc4a77674e740a",
     "grade": true,
     "grade_id": "testa_1_questao_loss_func",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1_questao_loss_func autograder_tests 0.1\n",
    "\n",
    "y = torch.zeros(3, 15, 8, 8)\n",
    "≈∑ = torch.zeros(3, 15, 8, 8, requires_grad=True)\n",
    "\n",
    "criterion = nanoyolo_loss(1, 1, 1, 1)\n",
    "\n",
    "loss = criterion(≈∑, y)\n",
    "\n",
    "assert loss.shape == torch.Size([])\n",
    "assert abs(loss) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd04ef",
   "metadata": {},
   "source": [
    "A loss deve ter um gradiente e ser retropropag√°vel at√© $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aaf53b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcfc3adf7c16920a852312be75de1889",
     "grade": true,
     "grade_id": "testa_1b_questao_loss_func",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1b_questao_loss_func autograder_tests 0.1\n",
    "\n",
    "y1 = torch.rand(3, 15, 8, 8)\n",
    "≈∑1 = torch.rand(3, 15, 8, 8, requires_grad=True)\n",
    "criterion1b = nanoyolo_loss(1, 1, 1, 1)\n",
    "\n",
    "calculated_loss1b = criterion1b(≈∑1, y1)\n",
    "calculated_loss1b.backward()\n",
    "\n",
    "assert calculated_loss1b.requires_grad\n",
    "assert torch.linalg.norm(≈∑1.grad) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb95cf0",
   "metadata": {},
   "source": [
    "Vamos verificar se apenas quando as probabilidade s√£o diferente a loss √© realmente a da Entropia Cruzada Bin√°ria (`binary_cross_entropy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ae69f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13201ecfd08938401dae23c2e3783ab",
     "grade": true,
     "grade_id": "testa_2_questao_loss_func",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_2_questao_loss_func autograder_tests 0.2\n",
    "\n",
    "y2 = torch.zeros(3, 15, 8, 8)\n",
    "≈∑2 = torch.zeros(3, 15, 8, 8)\n",
    "\n",
    "y2[:, 0] = torch.rand(8, 8)\n",
    "≈∑2[:, 0] = torch.rand(8, 8)\n",
    "bce_loss = F.binary_cross_entropy(≈∑2[:, 0], y2[:, 0])\n",
    "\n",
    "criterion2 = nanoyolo_loss(3, 1, 1, 1)\n",
    "loss2 = criterion2(≈∑2, y2)\n",
    "\n",
    "assert abs(loss2 - 3 * bce_loss) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7db64",
   "metadata": {},
   "source": [
    "Agora quando a localiza√ß√£o do centroide estiver errada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc36a27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5206e89f8705b24dbb089840f9002c6f",
     "grade": true,
     "grade_id": "testa_3_questao_loss_func",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_3_questao_loss_func autograder_tests 0.2\n",
    "\n",
    "y3 = torch.zeros(4, 10, 9, 9)\n",
    "y3[:, 0] = 1\n",
    "≈∑3 = y3.clone().detach()\n",
    "\n",
    "y3[:, 1:3] = torch.rand(2, 9, 9)\n",
    "≈∑3[:, 1:3] = torch.rand(2, 9, 9)\n",
    "mse_loss = F.mse_loss(≈∑3[:, 1:3], y3[:, 1:3])\n",
    "\n",
    "criterion3 = nanoyolo_loss(1, 7, 1, 1)\n",
    "loss3 = criterion3(≈∑3, y3)\n",
    "\n",
    "assert abs(loss3 - 7 * mse_loss) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66bd46",
   "metadata": {},
   "source": [
    "Mas o c√°lculo de todos os outros valores est√° condicionado √†s probabilidades verdadeiras\n",
    "\n",
    "OBS: N√£o se esque√ßa de testar a loss de MSE da largura e da altura tamb√©m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428c20f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb98cc466d68b7b3f580b2ae5194cad1",
     "grade": true,
     "grade_id": "testa_4_questao_loss_func",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_4_questao_loss_func autograder_tests 0.2\n",
    "\n",
    "y4 = torch.zeros(4, 9, 6, 6)\n",
    "≈∑4 = torch.zeros(4, 9, 6, 6)\n",
    "\n",
    "≈∑4[:, 1:] = torch.rand(4, 8, 6, 6)\n",
    "\n",
    "criterion4 = nanoyolo_loss(1, 1, 1, 1)\n",
    "loss4 = criterion4(≈∑4, y4)\n",
    "\n",
    "assert abs(loss4) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851622ad",
   "metadata": {},
   "source": [
    "Agora para a classifica√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c24cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e14b84d9138da244723b0b7ee4f9cc58",
     "grade": true,
     "grade_id": "testa_5_questao_loss_func",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_5_questao_loss_func autograder_tests 0.2\n",
    "\n",
    "y5 = torch.zeros(5, 9, 6, 6)\n",
    "y5[:, 0] = 1\n",
    "≈∑5 = y5.clone().detach()\n",
    "\n",
    "y5[:, 5:] = torch.rand(5, 4, 6, 6)\n",
    "≈∑5[:, 5:] = torch.rand(5, 4, 6, 6)\n",
    "ce_loss = F.cross_entropy(≈∑5[:, 5:], y5[:, 5:])\n",
    "\n",
    "criterion5 = nanoyolo_loss(1, 1, 1, 666)\n",
    "loss5 = criterion5(≈∑5, y5)\n",
    "\n",
    "assert abs(loss5 - 666 * ce_loss) < 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20817de",
   "metadata": {},
   "source": [
    "Juntando tudo ao mesmo tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54196647",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20b4adb3cefa8df313ba8c0e76729cea",
     "grade": true,
     "grade_id": "testa_6_questao_loss_func",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_6_questao_loss_func autograder_tests 1\n",
    "\n",
    "y6 = tensor([[0.4108, 0.1717, 0.0069, 0.1393, 0.1146, 0.4914, 0.8634],\n",
    "[0.8840, 0.3539, 0.6189, 0.7642, 0.7592, 0.1080, 0.7073]]).reshape(2, 7, 1, 1)\n",
    "≈∑6 = tensor([[0.8075, 0.1843, 0.3749, 0.3511, 0.9455, 0.5990, 0.9024],\n",
    "[0.2924, 0.8519, 0.9057, 0.8252, 0.5625, 0.7529, 0.9267]]).reshape(2, 7, 1, 1)\n",
    "\n",
    "criterion6 = nanoyolo_loss(1, 2, 3, 4)\n",
    "loss6 = criterion6(≈∑6, y6)\n",
    "\n",
    "assert abs(loss6 - 3.1717855) < 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a8d65",
   "metadata": {},
   "source": [
    "## Supress√£o N√£o-Maximal (4 pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846be84",
   "metadata": {},
   "source": [
    "**Explica√ß√£o sobre o assunto**\n",
    "\n",
    "Agora chegamos na √∫ltima quest√£o! J√° que sabemos como construir o tensor a partir de uma lista de BBs, temos que saber fazer o inverso tamb√©m: construir uma lista de BBs a partir de um tensor de sa√≠da.\n",
    "\n",
    "S√≥ que n√≥s estaremos trabalhando com a sa√≠da estimada da rede, e n√£o com a sa√≠da esperada que n√≥s construimos l√° em cima perfeitamente (apesar de que podemos us√°-la para fazer um teste). Dessa forma, teremos muito ru√≠do! Sobretudo probabilidades que n√£o ser√£o nem 0 nem 1, mas algo intermedi√°rio.\n",
    "\n",
    "Assim como primeiro passo, n√≥s temos que descartar todos os elementos do grid que tiverem probabilidade menor do que 1 (opera√ß√£o abaixo apenas ilustrativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((3, 4)) < 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd169e11",
   "metadata": {},
   "source": [
    "Depois devemos des-normalizar os valores de posi√ß√£o e de tamanho da bounding box (opera√ß√£o abaixo apenas ilustrativa, fa√ßa o inverso da quest√£o 1), para obter o seu tamanho em pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a33ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.rand(2, 3, 4)) * tensor([[[2]],[[3]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65804c",
   "metadata": {},
   "source": [
    "S√≥ depois disso que ent√£o aplicamos a supress√£o n√£o-maximal, que consiste, por classe, encontrar a BB de maior probabilidade e ir iterando sobre as outras. Deve-se descartar as bounding boxes que tenham grande sobreposi√ß√£o com as outras.\n",
    "\n",
    "Essa m√©trica de sobreposi√ß√£o n√≥s chamamos de Intersection over Union (IoU) e pode ser facilmente calculada abaixo encontrando os v√©rtices do topo esquerdo (max sobre os v√©rtices m√≠nimos) e do fundo direito (min sobre os vertices m√°ximos), conforme descrito na figura abaixo\n",
    "\n",
    "![IoU](https://ia.gam.dev/cm203/23/lab06/iou.png)\n",
    "\n",
    "<details><summary><b>CLIQUE EM MIM (exemplos DE IoU para matching) </b></summary>\n",
    "<p>\n",
    "<img src=\"https://b2633864.smushcdn.com/2633864/wp-content/uploads/2016/09/iou_examples.png?lossy=2&strip=1&webp=1\" alt=\"IoU\"/>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "O fun√ß√£o IoU abaixo implementa essa opera√ß√£o passo-a-passo (pode servir de inspira√ß√£o para os broadcastings da sua des-normaliza√ß√£o), ela recebe duas bounding-boxes na forma de lista de floats e retorna um escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96262f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(bbox1, bbox2):\n",
    "    boxes = np.vstack([bbox1, bbox2])        #  (2, 4)\n",
    "    areas = np.prod(boxes[:, 2:4], axis=-1)  #    (2,)\n",
    "    topo_esq = np.max(boxes[:, 0:2], axis=0) #    (2,)\n",
    "    fundo_dir = np.min(boxes[:, 0:2]+boxes[:, 2:4], axis=0)\n",
    "    if np.any(fundo_dir <= topo_esq):\n",
    "        return 0\n",
    "    intersection = np.prod(fundo_dir-topo_esq)\n",
    "    union = np.sum(areas) - intersection\n",
    "    return intersection / union\n",
    "\n",
    "IoU([0., 0, 20, 30], [5., 0, 20, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f01efc",
   "metadata": {},
   "source": [
    "Dica para facilitar a sua implementa√ß√£o:\n",
    "\n",
    "Na realidade, o processo de descarte do primeiro passo j√° pode ser realizado de forma impl√≠cita ao percorrer o loop dos valores de probabilidade j√° ordenados. Veja um exemplo do loop abaixo com o sort que lista os valores, o seu √≠ndice na ordem crescente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for valores, indices in zip(*torch.sort(torch.rand(2,2).flatten())):\n",
    "    print(valores, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f62b97",
   "metadata": {},
   "source": [
    "Os valores das posi√ß√µes `xy` do grid j√° s√£o disponibilizados no in√≠cio da fun√ß√£o abaixo, e recomendo utiliz√°-lo para o c√°lculo da desnormaliza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85742192",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(torch.meshgrid(torch.arange(3), torch.arange(4), indexing='ij')[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b42164",
   "metadata": {},
   "source": [
    "**Enunciado da Quest√£o**\n",
    "\n",
    "Implemente a fun√ß√£o `recupera_lista` abaixo, que dado um tensor que representa o grid de sa√≠da da nossa rede neural, retorna uma lista de BBs e uma lista de suas classes associadas ao grid ap√≥s procedimento de supress√£o n√£o-maximal. Se tiver d√∫vidas sobre NMS, veja o v√≠deo abaixo do Andrew Ng:\n",
    "\n",
    "[![Video Explaining NMS](https://i.ytimg.com/vi/VAo84c1hQX8/maxresdefault.jpg)](https://www.youtube.com/watch?v=VAo84c1hQX8 \"Video Explaining NMS - Click to Watch!\")\n",
    "\n",
    "**Sugiro fortemente implementar a fun√ß√£o aos poucos (TDD)**\n",
    "\n",
    "**N√ÉO** use LLMs (ChatGPT) para pegar a resposta pronta. **N√ÉO** pesquise a resposta pronta na internet.\n",
    "\n",
    "**Pode** olhar a documenta√ß√£o das bibliotecas (PyTorch, FastAI, mas todas as fun√ß√µes que voc√™ precisa est√° nas **dicas**) e **pode** (aconselhado) olhar o material de aula (slides e refer√™ncias).\n",
    "\n",
    "<details><summary><b>Dica para a resposta</b></summary>\n",
    "<p>\n",
    "\n",
    "Use a fun√ß√£o `IoU` da explica√ß√£o e a forma e percorrer o loop j√° ordenado pelas probabilidades.\n",
    "\n",
    "Fun√ß√µes pertinentes da biblioteca: `torch.exp`, `torch.cat`, `torch.sort` (use a ordem correta com o argumento `descending`)\n",
    "\n",
    "Use `.numpy().tolist()` para converter um tensor para uma lista, e `.item()` para pegar o valor escalar do tensor (de rank 0)\n",
    "\n",
    "Use `lista4.append(elem76)` para adicionar um elemento na lista de Python.\n",
    "\n",
    "A minha implementa√ß√£o final (dentro do solution) ficou com 15 linhas. Seja esperto no broadcasting e nos slices.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3fddd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92f201c6d37ab40ae218d83d258cdc45",
     "grade": false,
     "grade_id": "questao_nms",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# questao_nms autograded_answer\n",
    "\n",
    "def recupera_lista(saida: Tensor, S: int, norms_bb: Tensor, thres=0.3, iou_nms=0.5):\n",
    "    \"\"\"Extrai a lista de BBs e realiza a supress√£o n√£o maximal.\n",
    "    \n",
    "    Args:\n",
    "        saida: tensor de shape (1+4+C, H_g, W_g) que representa o grid de BBs da rede\n",
    "        S: tamanho do grid em pixels\n",
    "        norms_bb: largura e altura m√©dia (fator de normaliza√ß√£o) das BBs\n",
    "        thres: limiar (threshold) dos valores de probabilidade, se a probabilidade\n",
    "            for abaixo desse limiar, o candidato deve ser descartado\n",
    "        iou_nms: valor de IoU para supress√£o n√£o-maximal (NMS), se o IoU for acima\n",
    "            desse limiar o candidato deve ser descartado\n",
    "    \n",
    "    Returns:\n",
    "        lista de bouding boxes definidas pelo v√©rtice do topo esquerdo, largura e altura (x, y, w, h)\n",
    "        lista de classes: cada classe √© um inteiro entre 0 e C-1 inclusive\n",
    "    \"\"\"\n",
    "    Ct, Hg, Wg = saida.shape\n",
    "    H, W = S * Hg, S * Wg\n",
    "    C = Ct -5\n",
    "    lista_bbs, lista_classes = [], []\n",
    "    xy = torch.stack(torch.meshgrid(torch.arange(Hg), torch.arange(Wg), indexing='ij')[::-1])\n",
    "    # WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ec83b",
   "metadata": {},
   "source": [
    "Se voc√™ usou uma LLM, escreva a sua conversa com ela aqui nesta pr√≥pria c√©lula de texto (copie a conversa inteira) ou exporte o link da conversa:\n",
    "\n",
    "**Escreva aqui**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0ee7e",
   "metadata": {},
   "source": [
    "Para um tensor de entrada com probabilidades nulas, deve retornar uma lista vazia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214545a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dedfcde781cfe690a0765a9acd4d30b6",
     "grade": true,
     "grade_id": "testa_1_questao_nms",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_1_questao_nms autograder_tests 0.2\n",
    "\n",
    "tensor_teste = torch.zeros(15, 10, 10)\n",
    "\n",
    "lista_bbs, categorias = recupera_lista(tensor_teste, 100, tensor([1., 1.]))\n",
    "\n",
    "assert lista_bbs == []\n",
    "assert categorias == []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f839f9e",
   "metadata": {},
   "source": [
    "Para um tensor com um grid unit√°rio, e probabilidade acima do threshold, deve realizar a desnormaliza√ß√£o dos valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271016d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "598e2db7a9ae19eb52ca87b74a58951d",
     "grade": true,
     "grade_id": "testa_2_questao_nms",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_2_questao_nms autograder_tests 0.3\n",
    "\n",
    "tensor_teste2 = tensor([1, -0.1, 0.2, np.log(1.5), np.log(0.5), 0, 0, 1, 0]).reshape(9, 1, 1)\n",
    "\n",
    "lista_bbs2, categorias2 = recupera_lista(tensor_teste2, 100, tensor([50., 50.]))\n",
    "\n",
    "assert len(lista_bbs2) == 1\n",
    "assert len(categorias2) == 1\n",
    "assert type(lista_bbs2[0]) == list\n",
    "assert np.linalg.norm(array(lista_bbs2[0]) - array([\n",
    "    45-75/2, 60-25/2, 75, 25\n",
    "])) < 1e-5\n",
    "assert type(categorias2[0]) == int\n",
    "assert categorias2[0] == 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c18d9",
   "metadata": {},
   "source": [
    "Deve retornar uma lista de BBs para m√∫ltiplos elementos do grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f4bc7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a48edea3cf4eaf823512aa9925e82c35",
     "grade": true,
     "grade_id": "testa_3_questao_nms",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_3_questao_nms autograder_tests 0.5\n",
    "\n",
    "tensor_teste3 = tensor([\n",
    "    [0.9, 0, 0, np.log(1.1), np.log(1.2), 0.8, 0.1, 0, 0.1],\n",
    "    [0.7, 0, 0, np.log(1.2), np.log(1.1), 0.1, 0.1, 0, 0.8],\n",
    "    [0.5, 0, 0, np.log(1.1), np.log(1.2), 0, 0.1, 0.8, 0.1],\n",
    "    [0.2, 0, 0, np.log(1.1), np.log(1.2), 0, 0.1, 0.8, 0.1],\n",
    "]).transpose(0, 1).reshape(9, 2, 2)\n",
    "bbs_esperados3 = [\n",
    "    [50-55, 50-60, 110, 120],\n",
    "    [150-60, 50-55, 120, 110],\n",
    "    [50-55, 150-60, 110, 120]\n",
    "]\n",
    "\n",
    "lista_bbs3, categorias3 = recupera_lista(tensor_teste3, 100, tensor([100., 100.]), thres=0.3)\n",
    "\n",
    "assert len(lista_bbs3) == 3\n",
    "assert len(categorias3) == 3\n",
    "assert np.linalg.norm(array(lista_bbs3) - array(bbs_esperados3)) < 1e-3\n",
    "assert np.all(array(categorias3) == array([0, 3, 2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4da6d",
   "metadata": {},
   "source": [
    "Ainda no mesmo exemplo anterior, vamos deixar as BBs com um overlapping muito grande entre elas, n√≥s devemos fazer NMS, atente que a ordem de retorno da BBs deve ser pela ordem das probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3782a32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93c48952a28274100917025ffd800d51",
     "grade": true,
     "grade_id": "testa_4_questao_nms",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_4_questao_nms autograder_tests 1\n",
    "\n",
    "tensor_teste4 = tensor([\n",
    "    [0.7,  0.99,  0.99, np.log(1.9), np.log(1.9), 1, 0],\n",
    "    [0.6, -0.99,  0.99, np.log(1.9), np.log(1.9), 1, 0],\n",
    "    [0.9,  0.99, -0.99, np.log(1.9), np.log(1.9), 1, 0],\n",
    "    [0.5, -0.99, -0.99, np.log(1.9), np.log(1.9), 1, 0],\n",
    "]).transpose(0, 1).reshape(7, 2, 2)\n",
    "bbs_esperados4 = [\n",
    "    [99.5-190/2, 100.5-190/2, 190, 190],\n",
    "]\n",
    "\n",
    "lista_bbs4, categorias4 = recupera_lista(tensor_teste4, 100, tensor([100., 100.]), thres=0.3)\n",
    "\n",
    "assert len(lista_bbs4) == 1\n",
    "assert len(categorias4) == 1\n",
    "assert np.linalg.norm(array(lista_bbs4) - array(bbs_esperados4)) < 1e-3\n",
    "assert categorias4[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0539e",
   "metadata": {},
   "source": [
    "Finalmente, vamos aplicar em um exemplo maior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbb8c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a08e469e9883c55bd44d78471c55139b",
     "grade": true,
     "grade_id": "testa_5_questao_nms",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testa_5_questao_nms autograder_tests 2\n",
    "\n",
    "tensor_teste5 = tensor([\n",
    "[0.7,  0.99,  0.99, np.log(1.9), np.log(2), 1, 0], [0.8, -0.99,  0.99, np.log(1.9), np.log(2), 1, 0],\n",
    "[0.6,  0.99, -0.99, np.log(1.9), np.log(2), 1, 0], [0.9, -0.91, -0.99, np.log(2), np.log(1.9), 0, 1],\n",
    "[0.5,     0, -0.99, np.log(1.9), np.log(2), 1, 0], [0.2, -0.99, -0.99, np.log(1.9), np.log(2), 1, 0],\n",
    "[0.7,  0.99,     0, np.log(2),   np.log(2), 0, 1], [1.0, -0.99,     0, np.log(2),   np.log(2), 0, 1],\n",
    "]).transpose(0, 1).reshape(7, 4, 2)\n",
    "bbs_esperados5 = [\n",
    "    [141, 640, 120, 120],\n",
    "    [149, 144, 120, 114],\n",
    "    [144, 139, 114, 120],\n",
    "    [43,  341, 114, 120]\n",
    "]\n",
    "\n",
    "lista_bbs5, categorias5 = recupera_lista(tensor_teste5, 200, tensor([60., 60.]), thres=0.3, iou_nms=0.4)\n",
    "\n",
    "assert len(lista_bbs5) == 4\n",
    "assert len(categorias5) == 4\n",
    "assert np.linalg.norm(array(lista_bbs5) - array(bbs_esperados5)) < 1e-3\n",
    "assert np.all(array(categorias5) == array([1, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c586cf0",
   "metadata": {},
   "source": [
    "Veja se a sua resposta est√° fazendo sentido, lembre-se de que classes diferentes s√£o independentes no NMS (assim pode ter um verde com alto IoU em rela√ß√£o a um azul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6378c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dado({'image': Image.fromarray(np.zeros((800, 400, 3), dtype=np.uint8)), \n",
    "           'objects': {'bbox': lista_bbs5, 'category': categorias5}}, grid=200)\n",
    "tensor_teste5[0], lista_bbs5, categorias5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24452d41",
   "metadata": {},
   "source": [
    "## Treinando de Verdade! (Use GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4019c29",
   "metadata": {},
   "source": [
    "Agora vamos usar o FastAI para treinar a rede a partir do transfer learning da outra que era apenas de classifica√ß√£o. Primeiro vamos definir o nosso DataBlock do FastAI:\n",
    "\n",
    "Vamos definir a nossa fun√ß√£o `get_items` que simplesmente retorna uma lista dos itens do dataset, mas que tamb√©m marca com uma flag os itens de treinamento (obs: essa implementa√ß√£o acabou ficando bronca por que a mem√≥ria fica alocada na imagem quando ele acessa o dicion√°rio):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_dataset_items(data: dict):\n",
    "    train = L(data.get('train'))\n",
    "    for d in train:\n",
    "        d['train'] = True\n",
    "    return (train + L(data.get('validation'))).shuffle()\n",
    "\n",
    "its = get_dict_dataset_items({'train': [{0:'ok'}, {0:'bom'}, {0:'nice'}, {0:'wut'}, {0:'go'}], \n",
    "                              'validation': [{0:'dis'}, {0:'mau'}, {0:'est'}]})\n",
    "its"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baec9cb",
   "metadata": {},
   "source": [
    "E o nosso splitter que v√™ a flag para retornar os √≠ndices de treinamento e de valida√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_splitter(data_list):\n",
    "    train, valid = L(), L()\n",
    "    for i, datum in enumerate(data_list):\n",
    "        if datum.get('train'):\n",
    "            train.append(i)\n",
    "        else:\n",
    "            valid.append(i)\n",
    "    return L(train), L(valid)\n",
    "\n",
    "train_val_splitter(its)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8a88c",
   "metadata": {},
   "source": [
    "O FastAI padronizou uma tupla de bounding boxes pelos v√©rtices $(x_0, y_0, x_1, y_1)$, em vez de ser com largura e altura $(x_0, y_0, w, h)$. Assim vamos transformar para o formato dele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_from_item(data_item):\n",
    "    bbs = array(data_item['objects']['bbox'])\n",
    "    bbs[..., 2:] += bbs[..., :2]\n",
    "    return bbs\n",
    "\n",
    "get_bb_from_item({'objects': {'bbox': [[10, 12, 5, 6], [8, 9, 2, 3]]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b61da7",
   "metadata": {},
   "source": [
    "E tamb√©m vamos criar o nosso *transform* final que ir√° chamar a primeira fun√ß√£o `monta_grid_detecta` que voc√™s implementaram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f56c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformaBB(ItemTransform):\n",
    "    def __init__(self, C=4, grid_size=32, norms_bb=tensor([55.5, 84.6]), thres=0.3, iou_nms=0.2):\n",
    "        self.C = C\n",
    "        self.grid_size = grid_size\n",
    "        self.norms_bb = norms_bb\n",
    "        self.thres = thres\n",
    "        self.iou_nms = iou_nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5417ee",
   "metadata": {},
   "source": [
    "O m√©todo `encodes` (esse nome √© importante para o FastAI) vai receber uma tupla com a imagem, as bounding boxes e as categorias e deve formar o grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(TransformaBB)\n",
    "def encodes(self: TransformaBB, img_bb_cat):\n",
    "    if len(img_bb_cat) < 3:\n",
    "        return img_bb_cat\n",
    "    img, bbs, cats = img_bb_cat\n",
    "    H, W = img.shape\n",
    "    bbs[..., 2:] -= bbs[..., :2]\n",
    "    saida_esperada = monta_grid_detecta(bbs, cats, self.C, W, H, self.grid_size, self.norms_bb)\n",
    "    return img, saida_esperada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cceaf9d",
   "metadata": {},
   "source": [
    "O m√©todo `decodes` (nome √© importante) faz o inverso do encodes (ele √© usado para visualiza√ß√£o ou para infer√™ncia). Dessa forma n√≥s temos uma transforma√ß√£o que faz parte do Pipeline do FastAI e que consegue trabalhar nos dois sentidos: codificar um grid a partir de uma lista (*encoding*) e decodificar o grid gerando a lista (*decoding*).\n",
    "\n",
    "√â por isso que era t√£o importante essas duas fun√ß√µes que voc√™s implementaram, justamente para poder gerar a entrada esperada para treinar a rede e depois tamb√©m para poder compreender a sa√≠da da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88623c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(TransformaBB)\n",
    "def decodes(self: TransformaBB, img_grid):\n",
    "    img, grid = img_grid\n",
    "    bbs, cats = recupera_lista(grid, self.grid_size, self.norms_bb, self.thres, self.iou_nms)\n",
    "    bbs = TensorBBox(bbs)\n",
    "    bbs[..., 2:] += bbs[..., :2]\n",
    "    return img, bbs, TensorMultiCategory(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76526e",
   "metadata": {},
   "source": [
    "Ent√£o vamos instanciar o nosso DataBlock e o nosso DataLoader, perceba que s√£o tr√™s tipos de blocos diferentes: o `ImageBlock` que voc√™s j√° conhecem que representa uma imagem, o `BBoxBlock` que representa uma lista de bounding boxes, e o `BBoxLblBlock` que representa uma lista de labels associado a cada bounding box respectivamente.\n",
    "\n",
    "Ent√£o utilizamos as nossas fun√ß√µes que definimos anteriormente, observe com cuidado o c√≥digo abaixo, aten√ß√£o para o `item_tfms=TransformaBB()` que chama a transforma√ß√£o que n√≥s criamos para poder montar o nosso grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e61ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBoxBlock_nopad = TransformBlock(type_tfms=TensorBBox.create)\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks = (ImageBlock, BBoxBlock_nopad, BBoxLblBlock(add_na=False)),\n",
    "    get_items = get_dict_dataset_items,\n",
    "    splitter = train_val_splitter,\n",
    "    n_inp = 1,\n",
    "    get_x = lambda o: o['image'],\n",
    "    get_y = [get_bb_from_item, lambda o: o['objects']['category']],\n",
    "    item_tfms=TransformaBB(),\n",
    "    batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    ")\n",
    "\n",
    "if RETRAIN:\n",
    "    data = cs_dataset\n",
    "else:\n",
    "    data = {'train': [cs_dataset['train'][i] for i in [0, 2, 5, 10, 11, 50, 100, 103]]}\n",
    "\n",
    "dloader = dblock.dataloaders(data, bs=32 if RETRAIN else 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee642ad2",
   "metadata": {},
   "source": [
    "S√≥ que o FastAI √© bem esperto e faz muitas coisas ao mesmo tempo, al√©m da transforma√ß√£o que pedimos, ele colocou mais, associadas aos blocos. Veja as transforma√ß√µes que ele executa, respectivamente, logo depois que ele pega um item (`after_item`), em seguida antes de aglutinar os items em um batch `before_batch`, e depois de ter aglutinado os items em um batch `after_batch`.\n",
    "\n",
    "Voc√™ consegue encontrar o `TransformaBB` abaixo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e50622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader.after_item,  dloader.before_batch, dloader.after_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00664e9b",
   "metadata": {},
   "source": [
    "Veja como os dados chegam ao modelo. Perceba o shape dos tensores, √© justamente a imagem e o grid, depois de terem passado pela sequ√™ncia dos Pipelines a√≠ em cima. Perceba tamb√©m que o FastAI j√° cuidou para eles ficarem em GPU (se voc√™ tiver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dloader.train))\n",
    "x.shape, y.shape, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3741b2",
   "metadata": {},
   "source": [
    "Vamos ver o batch gerado pelo FastAI. Isso √© o resultado primeiro do `encode` e depois do `decode` (ambos tem que estar funcionando e casados no sentido de um fazer o inverso do outro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b54f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    dloader.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea313526",
   "metadata": {},
   "source": [
    "Vamos criar o nosso modelo de detec√ß√£o (que voc√™ implementou o `forward`) e carregar os pesos da rede que era apenas de classifica√ß√£o nele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc760ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvDect(4)\n",
    "\n",
    "classification_weights = {}\n",
    "if RETRAIN:\n",
    "    url = \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_22k_224.pth\"\n",
    "    classification_weights = torch.hub.load_state_dict_from_url(url=url, map_location=\"cpu\", check_hash=True)['model']\n",
    "\n",
    "transfer_learning(model, classification_weights)\n",
    "\n",
    "[(nome, param.requires_grad) for nome, param in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbebb2",
   "metadata": {},
   "source": [
    "Em seguida vamos criar o `Learner` do FastAI, que encapsula tanto o nosso modelo do Pytorch, quanto o dataloader do FastAI, e a loss function, al√©m das m√©tricas e outros detalhes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dloader, model, nanoyolo_loss(1, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f450c17",
   "metadata": {},
   "source": [
    "O FastAI implementa o algoritmo de busca de learning rate ([aula 3, slide 29](https://docs.google.com/presentation/d/1pbXPJvpGoDK03KsazRf3D99-FXNd2FLcXpIVPl797PA/edit?pli=1#slide=id.g267c62e9f27_1_303)), que √© crucial para treinar grandes modelos, √© muito mais inteligente do que ficar treinando v√°rias vezes com learning rates diferentes. Veja abaixo:\n",
    "\n",
    "**(Use GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    learner.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ba2d0",
   "metadata": {},
   "source": [
    "Vamos ser um pouco mais audazes e colocar um learning rate maior do que ele sugeriu. Mas tenha cuidado, pois o gr√°fico do `lr_find` √© de uma *loss smoothed*, ou seja, ela tem **atraso**, ent√£o tem que ser antes do ponto de inflex√£o.\n",
    "\n",
    "Assim, executamos os loops de treinamento por N √©pocas por meio da fun√ß√£o abaixo, com a learning rate desejada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2deba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    learner.fit_one_cycle(2, 0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efdd6b6",
   "metadata": {},
   "source": [
    "Agora que as nossas √∫ltimas camadas j√° est√£o razoavelmente bem treinadas, podemos *descongelar* as camadas anteriores (que estavam com `require_grad=False`) e deixar a rede treinar por inteiro. Isso potencialmente permite com que a rede se adapte melhor ao nosso problema, treinando por inteiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    m.train()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "learner = Learner(dloader, model, nanoyolo_loss(1, 1, 1, 1))\n",
    "\n",
    "[(nome, param.requires_grad) for nome, param in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4142a1",
   "metadata": {},
   "source": [
    "E fazemos agora mais uma √©poca de treino, vamos usar um learning rate menor. Percebe que est√° demorando muito mais por √©poca, voc√™ consegue saber porque? Responda na c√©lula abaixo (obs: essa resposta discursiva n√£o vai contabilizar na nota, mas irei ler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1be3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    learner.fit_one_cycle(1, 0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c6ca3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b91661ea023220e1a07cb2e2bfe7e69b",
     "grade": true,
     "grade_id": "discursiva",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "WRITE YOUR SOLUTION HERE! (do not change this first line):\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**DISCURSIVE QUESTION**\n",
    "\n",
    "WRITE YOUR ANSWER HERE (do not delete this cell so the ID is not lost)\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8655378",
   "metadata": {},
   "source": [
    "Vamos ver os resultados no conjunto de valida√ß√£o, pode executar a c√©lula abaixo do `show_results` por v√°rias vezes, cada vez ser√£o imagens da valida√ß√£o aleat√≥rias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    learner.show_results() # me rode v√°rias vezes, imagens diferentes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b83c8",
   "metadata": {},
   "source": [
    "Vamos testar com outras imagens que eu peguei aleat√≥riamente da internet! Sinta-se √† vontade para trocar o nome da imagem ou at√© para baixar a sua pr√≥pria ou tirar um print do seu jogo (*para fins puramente de pesquisa, √© claro* üòè)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_teste = None\n",
    "if RETRAIN:\n",
    "    img_teste = PILImage.create(base_path/'cs02.jpg') # cs00.jpg, ... cs08.jpg\n",
    "img_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfd89d",
   "metadata": {},
   "source": [
    "Basta executar o m√©todo `predict` com a nossa imagem do Pillow, infelizmente ele j√° n√£o faz o plot autom√°tico igual o show_results, mas podemos n√≥s mesmos ver os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_predict_teste = None\n",
    "if RETRAIN:\n",
    "    resultado_predict_teste = learner.predict(img_teste)\n",
    "resultado_predict_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1bfa5",
   "metadata": {},
   "source": [
    "Vamos usar a nossa pr√≥pria fun√ß√£o para ver os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    bbs_teste, cats_teste = resultado_predict_teste[0][1]\n",
    "    bbs_teste = bbs_teste.detach().clone()\n",
    "    bbs_teste[:, 2:] -= bbs_teste[:, :2]\n",
    "    plot_dado({'image': img_teste, 'objects': {'bbox': bbs_teste, 'category': cats_teste}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    torch.save(model.state_dict(), base_path/'treinado_meu.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc685bac",
   "metadata": {},
   "source": [
    "Ainda h√° pontos de melhoria para o lab, mas j√° ficou bem extenso ent√£o vou deixar para apresentar no pr√≥ximo ou deixar citado:\n",
    "\n",
    "√â interessante colocar um Augmentation no treino e treinar por mais √©pocas tamb√©m. Como n√≥s treinamos por poucas √©pocas a falta do data augmentation n√£o foi t√£o grave assim. Mas para se ter um resultado melhor √© imprescind√≠vel us√°-lo. O aug_transforms era pensado para o batch_tfms, mas n√≥s temos que colocar as augmentations no item_tfms antes da nossa cria√ß√£o do grid, e ele deve alterar tanto a imagem quanto as bounding boxes da mesma forma.\n",
    "\n",
    "Outro ponto important√≠ssimo que tamb√©m n√£o foi explorado s√£o as m√©tricas de detec√ß√£o: o MaP (mean average precision), e tamb√©m um gr√°fico de precision vs recall para os diferentes thresholds.\n",
    "\n",
    "Al√©m disso o nosso modelo √© bem simples, na quest√£o de ter apenas uma bounding box por elemento do grid, al√©m de ter uma fun√ß√£o custo simplificada que n√£o leva em considera√ß√£o o IoU. Inclusive deixo essas melhorias como propostas para o trabalho do exame!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8625b",
   "metadata": {},
   "source": [
    "# Your data and feedback:\n",
    "\n",
    "Write a feedback for the lab so we can make it better for the next years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a036cf",
   "metadata": {},
   "source": [
    "In the following variables, write the number of hours spent on this lab, the perceived difficulty, and the expected grade (you may delete the `raise` and the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84cf22",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f613d80a345c28aaf937672ec9e9f5",
     "grade": true,
     "grade_id": "meta_eval",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# meta_eval manual_graded_answer 0\n",
    "\n",
    "horas_gastas = None    # 1.5   - Float number with the number of hours spent \n",
    "dificuldade_lab = None # 0     - Float number from 0.0 to 10.0 (inclusive)\n",
    "nota_esperada = None   # 10    - Float number from 0.0 to 10.0 (inclusive)\n",
    "\n",
    "# WRITE YOUR CODE HERE! (you can delete this comment, but do not delete this cell so the ID is not lost)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e85e2",
   "metadata": {},
   "source": [
    "Write below other comments or feedbacks about the lab. If you did not understand anything about the lab, please also comment here.\n",
    "\n",
    "If you find any typo or bug in the lab, please comment below so we can fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4baf2c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc6431aff9a971fe5ed82c62bc668c96",
     "grade": true,
     "grade_id": "meta_eval_discursivo",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "WRITE YOUR SOLUTION HERE! (do not change this first line):\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**DISCURSIVE QUESTION**\n",
    "\n",
    "WRITE YOUR ANSWER HERE (do not delete this cell so the ID is not lost)\n",
    "\n",
    "**ATTENTION**\n",
    "\n",
    "**ATTENTION**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98549e",
   "metadata": {},
   "source": [
    "**End of the lab!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
